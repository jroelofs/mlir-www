<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MLIR</title><link>https://mlir.llvm.org/</link><description>Recent content on MLIR</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 19 Oct 2017 15:26:15 +0000</lastBuildDate><atom:link href="https://mlir.llvm.org/index.xml" rel="self" type="application/rss+xml"/><item><title>FAQ</title><link>https://mlir.llvm.org/getting_started/Faq/</link><pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Faq/</guid><description>TODO</description></item><item><title>How to Contribute</title><link>https://mlir.llvm.org/getting_started/Contributing/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Contributing/</guid><description>Everyone is welcome to contribute to MLIR. There are several ways of getting involved and contributing including reporting bugs, improving documentation and tutorials.
Community Guidelines Please be mindful of the LLVM Code of Conduct , which pledges to foster an open and welcoming environment.
Contributing code We don&amp;rsquo;t accept pull-request on GitHub, instead we use Phabricator . At the moment you need to also join this group to enable build and test of your Phabricator revisions.</description></item><item><title>Developer Guide</title><link>https://mlir.llvm.org/getting_started/DeveloperGuide/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/DeveloperGuide/</guid><description>This document attempts to describe a few developer policies used in MLIR (such as coding standards used) as well as development approach (such as, testing methods).
Style guide MLIR follows the LLVM style guide. We also adhere to the following (which deviate from or are not specified in the LLVM style guide):
Adopts camelBack ; Uses Doxygen-style (///) comments for top-level and class member definitions, regardless of them being visible as public APIs.</description></item><item><title>Open Projects</title><link>https://mlir.llvm.org/getting_started/openprojects/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/openprojects/</guid><description>Below is a list of projects that can be suitable for Google Summer of Code (GSOC) or just for someone to get started with contributing to MLIR. See also the &amp;ldquo;beginner&amp;rdquo; issues on the bugtracker. If you&amp;rsquo;re interested in one of these projects, feel free to discuss it on the MLIR section of the LLVM forums or on the MLIR channel of the LLVM discord server. The mentors are indicative and suggestion of first point of contact for starting on these projects.</description></item><item><title>Glossary</title><link>https://mlir.llvm.org/getting_started/Glossary/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Glossary/</guid><description>This glossary contains definitions of MLIR-specific terminology. It is intended to be a quick reference document. For terms which are well-documented elsewhere, definitions are kept brief and the header links to the more in-depth documentation.
Block A sequential list of operations without control flow.
Also called a basic block .
Conversion The transformation of code represented in one dialect into a semantically equivalent representation in another dialect (i.e. inter-dialect conversion) or the same dialect (i.</description></item><item><title>Testing Guide</title><link>https://mlir.llvm.org/getting_started/TestingGuide/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/TestingGuide/</guid><description>Testing is an integral part of any software infrastructure. In general, all commits to the MLIR repository should include an accompanying test of some form. Commits that include no functional changes, such as API changes like symbol renaming, should be tagged with NFC(no functional changes). This signals to the reviewer why the change doesn&amp;rsquo;t/shouldn&amp;rsquo;t include a test.
MLIR generally separates testing into two main categories, Check tests and Unit tests.</description></item><item><title>Affine Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Affine/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Affine/</guid><description>This dialect provides a powerful abstraction for affine operations and analyses.
Polyhedral Structures Dimensions and Symbols Restrictions on Dimensions and Symbols Affine Expressions Affine Maps Semi-affine maps Integer Sets Operations Polyhedral Structures MLIR uses techniques from polyhedral compilation to make dependence analysis and loop transformations efficient and reliable. This section introduces some of the core concepts that are used throughout the document.</description></item><item><title>Background: declarative builders API</title><link>https://mlir.llvm.org/docs/EDSC/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/EDSC/</guid><description>The main purpose of the declarative builders API is to provide an intuitive way of constructing MLIR programmatically. In the majority of cases, the IR we wish to construct exhibits structured control-flow. Declarative builders provide an API to make MLIR construction and manipulation very idiomatic, for the structured control-flow case, in C++.
ScopedContext mlir::edsc::ScopedContext provides an implicit thread-local context, supporting a simple declarative API with globally accessible builders. These declarative builders are available within the lifetime of a ScopedContext.</description></item><item><title>Chapter 1: Toy Tutorial Introduction</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/</guid><description>The Chapters The Language The AST This tutorial runs through the implementation of a basic toy language on top of MLIR. The goal of this tutorial is to introduce the concepts of MLIR; in particular, how dialects can help easily support language specific constructs and transformations while still offering an easy path to lower to LLVM or other codegen infrastructure. This tutorial is based on the model of the LLVM Kaleidoscope Tutorial .</description></item><item><title>Chapter 2: Emitting Basic MLIR</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/</guid><description>Introduction: Multi-Level Intermediate Representation Interfacing with MLIR Opaque API Defining a Toy Dialect Defining Toy Operations Op vs Operation: Using MLIR Operations Using the Operation Definition Specification (ODS) Framework Complete Toy Example Now that we&amp;rsquo;re familiar with our language and the AST, let&amp;rsquo;s see how MLIR can help to compile Toy.
Introduction: Multi-Level Intermediate Representation Other compilers, like LLVM (see the Kaleidoscope tutorial ), offer a fixed set of predefined types and (usually low-level / RISC-like) instructions.</description></item><item><title>Chapter 3: High-level Language-Specific Analysis and Transformation</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/</guid><description>Optimize Transpose using C++ style pattern-match and rewrite Optimize Reshapes using DRR Creating a dialect that closely represents the semantics of an input language enables analyses, transformations and optimizations in MLIR that require high-level language information and are generally performed on the language AST. For example, clang has a fairly heavy mechanism for performing template instantiation in C++.
We divide compiler transformations into two categories: local and global.</description></item><item><title>Chapter 4: Enabling Generic Transformation with Interfaces</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/</guid><description>Background: Grappling with an Extensible IR Shape Inference: Preparing for Code Generation Inlining Intraprocedural Shape Inference Background: Grappling with an Extensible IR Through dialects, MLIR allows for the representation of many different levels of abstraction; the Toy dialect that we have previously defined is one such example. Though these different dialects may represent different abstractions, there is often a set of common transformations and analyses that we would like to perform.</description></item><item><title>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/</guid><description>Conversion Target Conversion Patterns Partial Lowering Design Considerations With Partial Lowering Complete Toy Example Taking Advantage of Affine Optimization At this point, we are eager to generate actual code and see our Toy language take life. We will use LLVM to generate code, but just showing the LLVM builder interface here wouldn&amp;rsquo;t be very exciting. Instead, we will show how to perform progressive lowering through a mix of dialects coexisting in the same function.</description></item><item><title>Chapter 6: Lowering to LLVM and CodeGeneration</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/</guid><description>Lowering to LLVM Conversion Target Type Converter Conversion Patterns Full Lowering CodeGen: Getting Out of MLIR Emitting LLVM IR Setting up a JIT In the previous chapter , we introduced the dialect conversion framework and partially lowered many of the Toy operations to affine loop nests for optimization. In this chapter, we will finally lower to LLVM for code generation.
Lowering to LLVM For this lowering, we will again use the dialect conversion framework to perform the heavy lifting.</description></item><item><title>Chapter 7: Adding a Composite Type to Toy</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/</guid><description>Defining a struct in Toy Defining a struct in MLIR Defining the Type Class Parsing and Printing Operating on StructType In the previous chapter , we demonstrated an end-to-end compilation flow from our Toy front-end to LLVM IR. In this chapter, we will extend the Toy language to support a new composite struct type.
Defining a struct in Toy The first thing we need to define is the interface of this type in our toy source language.</description></item><item><title>Conversion to the LLVM Dialect</title><link>https://mlir.llvm.org/docs/ConversionToLLVMDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/ConversionToLLVMDialect/</guid><description>Conversion from the Standard to the LLVM Dialect can be performed by the specialized dialect conversion pass by running
mlir-opt -convert-std-to-llvm &amp;lt;filename.mlir&amp;gt; It performs type and operation conversions for a subset of operations from standard dialect (operations on scalars and vectors, control flow operations) as described in this document. We use the terminology defined by the LLVM IR Dialect description throughout this document.
Type Conversion Scalar Types Index Type Vector Types Memref Types Function Types Calling Convention Function Signature Conversion Result Packing Calling Convention for memref C-compatible wrapper emission Repeated Successor Removal Default Memref Model Memref Descriptor Index Linearization Type Conversion Scalar Types Scalar types are converted to their LLVM counterparts if they exist.</description></item><item><title>Creating a Dialect</title><link>https://mlir.llvm.org/docs/CreatingADialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/CreatingADialect/</guid><description>CMake best practices TableGen Targets Library Targets CMake best practices Public dialects are typically separated into at least 3 directories:
mlir/include/mlir/Dialect/Foo (for public include files) mlir/lib/Dialect/Foo (for sources) mlir/lib/Dialect/Foo/IR (for operations) mlir/lib/Dialect/Foo/Transforms (for transforms) mlir/test/Dialect/Foo (for tests) Along with other public headers, the &amp;lsquo;include&amp;rsquo; directory contains a TableGen file in the ODS format , describing the operations in the dialect. This is used to generate operation declarations (FooOps.</description></item><item><title>Dialect 'affine' definition</title><link>https://mlir.llvm.org/docs/Dialects/AffineOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AffineOps/</guid><description>Operation definition affine.apply (AffineApplyOp) affine.for (AffineForOp) affine.if (AffineIfOp) affine.max (AffineMaxOp) affine.min (AffineMinOp) affine.parallel (AffineParallelOp) affine.prefetch (AffinePrefetchOp) affine.terminator (AffineTerminatorOp) Operation definition affine.apply (AffineApplyOp) affine apply operation
Description: The affine.apply operation applies an affine mapping to a list of SSA values, yielding a single SSA value. The number of dimension and symbol arguments to affine.apply must be equal to the respective number of dimensional and symbolic inputs to the affine mapping; the affine mapping has to be one-dimensional, and so the affine.</description></item><item><title>Dialect 'avx512' definition</title><link>https://mlir.llvm.org/docs/Dialects/AVX512/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AVX512/</guid><description>Operation definition avx512.mask.rndscale (avx512::MaskRndScaleOp) avx512.mask.scalef (avx512::MaskScaleFOp) Operation definition avx512.mask.rndscale (avx512::MaskRndScaleOp) Masked roundscale op
Description: The mask.rndscale op is an AVX512 specific op that can lower to the proper LLVMAVX512 operation: llvm.mask.rndscale.ps.512 or llvm.mask.rndscale.pd.512 instruction depending on the type of vectors it is applied to.
From the Intel Intrinsics Guide: Round packed floating-point elements in a to the number of fraction bits specified by imm, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).</description></item><item><title>Dialect 'fxpmath' definition</title><link>https://mlir.llvm.org/docs/Dialects/FxpMathOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/FxpMathOps/</guid><description>Operation definition fxpmath.clampis (fxpmath::ClampISOp) fxpmath.convertis (fxpmath::ConvertISOp) fxpmath.convertistof (fxpmath::ConvertISToFOp) fxpmath.real_add_ew (fxpmath::RealAddEwOp) fxpmath.compare (fxpmath::RealCompareZeroEwOp) fxpmath.real_div_ew (fxpmath::RealDivEwOp) fxpmath.real_matmul_bias (fxpmath::RealMatMulBiasOp) fxpmath.real_matmul (fxpmath::RealMatMulOp) fxpmath.real_mul_ew (fxpmath::RealMulEwOp) fxpmath.real_sub_ew (fxpmath::RealSubEwOp) fxpmath.real_unary_ew (fxpmath::RealUnaryEwOp) fxpmath.rounding_divide_by_potis (fxpmath::RoundingDivideByPotISOp) fxpmath.vs_saturating_rounding_doubling_high_mulis (fxpmath::VecScalarSaturatingRoundingDoublingHighMulISOp) Operation definition fxpmath.clampis (fxpmath::ClampISOp) Clamps a signed-integer like argument to a min/max range.
Description: Element-wise equivalent to: r = std::min(clamp_max, std::max(e, clamp_min))
Operands: operand: signless-integer-like Attributes: Attribute MLIR Type Description clamp_min IntegerAttr arbitrary integer attribute attribute clamp_max IntegerAttr arbitrary integer attribute attribute Results: «unnamed»: signless-integer-like fxpmath.</description></item><item><title>Dialect 'gpu' definition</title><link>https://mlir.llvm.org/docs/Dialects/GPUOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/GPUOps/</guid><description>Operation definition gpu.all_reduce (gpu::AllReduceOp) gpu.barrier (gpu::BarrierOp) gpu.block_dim (gpu::BlockDimOp) gpu.block_id (gpu::BlockIdOp) gpu.func (gpu::GPUFuncOp) gpu.module (gpu::GPUModuleOp) gpu.grid_dim (gpu::GridDimOp) gpu.launch_func (gpu::LaunchFuncOp) gpu.launch (gpu::LaunchOp) gpu.module_end (gpu::ModuleEndOp) gpu.return (gpu::ReturnOp) gpu.shuffle (gpu::ShuffleOp) gpu.terminator (gpu::TerminatorOp) gpu.thread_id (gpu::ThreadIdOp) gpu.yield (gpu::YieldOp) Operation definition gpu.all_reduce (gpu::AllReduceOp) Reduce values among workgroup.
Description: The &amp;ldquo;all_reduce&amp;rdquo; op reduces the value of every work item across a local workgroup. The result is equal for all work items of a workgroup.</description></item><item><title>Dialect 'linalg' definition</title><link>https://mlir.llvm.org/docs/Dialects/LinalgDoc/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/LinalgDoc/</guid><description>The linalg dialect groups together a set of types, operations and transformations that are useful to implement a structured abstraction on buffers and tensors. These abstractions are useful for transformations and can lower to scalar load/store and other operations or to more general library calls.
Additional Linalg Dialect Documentation and a Rationale Document are are also available and should be read first before going in the details of the op semantics.</description></item><item><title>Dialect 'llvm_avx512' definition</title><link>https://mlir.llvm.org/docs/Dialects/LLVMAVX512/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/LLVMAVX512/</guid><description>Operation definition llvm_avx512.mask.rndscale.pd.512 (LLVM::x86_avx512_mask_rndscale_pd_512) llvm_avx512.mask.rndscale.ps.512 (LLVM::x86_avx512_mask_rndscale_ps_512) llvm_avx512.mask.scalef.pd.512 (LLVM::x86_avx512_mask_scalef_pd_512) llvm_avx512.mask.scalef.ps.512 (LLVM::x86_avx512_mask_scalef_ps_512) Operation definition llvm_avx512.mask.rndscale.pd.512 (LLVM::x86_avx512_mask_rndscale_pd_512) Description: Operands: «unnamed»: LLVM dialect type «unnamed»: LLVM dialect type «unnamed»: LLVM dialect type «unnamed»: LLVM dialect type «unnamed»: LLVM dialect type Attributes: Results: res: LLVM dialect type llvm_avx512.mask.rndscale.ps.512 (LLVM::x86_avx512_mask_rndscale_ps_512) Description: Operands: «unnamed»: LLVM dialect type «unnamed»: LLVM dialect type «unnamed»: LLVM dialect type «unnamed»: LLVM dialect type «unnamed»: LLVM dialect type Attributes: Results: res: LLVM dialect type llvm_avx512.</description></item><item><title>Dialect 'loop' definition</title><link>https://mlir.llvm.org/docs/Dialects/LoopOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/LoopOps/</guid><description>Operation definition loop.for (ForOp) loop.if (IfOp) loop.parallel (ParallelOp) loop.reduce (ReduceOp) loop.reduce.return (ReduceReturnOp) loop.yield (YieldOp) Operation definition loop.for (ForOp) for operation
Description: The &amp;ldquo;loop.for&amp;rdquo; operation represents a loop taking 3 SSA value as operands that represent the lower bound, upper bound and step respectively. The operation defines an SSA value for its induction variable. It has one region capturing the loop body. The induction variable is represented as an argument of this region.</description></item><item><title>Dialect 'nvvm' definition</title><link>https://mlir.llvm.org/docs/Dialects/NVVMOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/NVVMOps/</guid><description>Operation definition nvvm.barrier0 (NVVM::Barrier0Op) nvvm.read.ptx.sreg.ntid.x (NVVM::BlockDimXOp) nvvm.read.ptx.sreg.ntid.y (NVVM::BlockDimYOp) nvvm.read.ptx.sreg.ntid.z (NVVM::BlockDimZOp) nvvm.read.ptx.sreg.ctaid.x (NVVM::BlockIdXOp) nvvm.read.ptx.sreg.ctaid.y (NVVM::BlockIdYOp) nvvm.read.ptx.sreg.ctaid.z (NVVM::BlockIdZOp) nvvm.read.ptx.sreg.nctaid.x (NVVM::GridDimXOp) nvvm.read.ptx.sreg.nctaid.y (NVVM::GridDimYOp) nvvm.read.ptx.sreg.nctaid.z (NVVM::GridDimZOp) nvvm.read.ptx.sreg.laneid (NVVM::LaneIdOp) nvvm.mma.sync (NVVM::MmaOp) nvvm.shfl.sync.bfly (NVVM::ShflBflyOp) nvvm.read.ptx.sreg.tid.x (NVVM::ThreadIdXOp) nvvm.read.ptx.sreg.tid.y (NVVM::ThreadIdYOp) nvvm.read.ptx.sreg.tid.z (NVVM::ThreadIdZOp) nvvm.vote.ballot.sync (NVVM::VoteBallotOp) nvvm.read.ptx.sreg.warpsize (NVVM::WarpSizeOp) Operation definition nvvm.barrier0 (NVVM::Barrier0Op) Description: Operands: Attributes: Results: nvvm.read.ptx.sreg.ntid.x (NVVM::BlockDimXOp) Description: Operands: Attributes: Results: res: LLVM dialect type nvvm.read.ptx.sreg.ntid.y (NVVM::BlockDimYOp) Description: Operands: Attributes: Results: res: LLVM dialect type nvvm.</description></item><item><title>Dialect 'omp' definition</title><link>https://mlir.llvm.org/docs/Dialects/OpenMPOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/OpenMPOps/</guid><description> Operation definition omp.barrier (omp::BarrierOp) Operation definition omp.barrier (omp::BarrierOp) barrier construct
Description: The barrier construct specifies an explicit barrier at the point at which the construct appears.
Operands: Attributes: Results:</description></item><item><title>Dialect 'quant' definition</title><link>https://mlir.llvm.org/docs/Dialects/QuantOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/QuantOps/</guid><description>Type definition UniformQuantizedType Operation definition quant.const_fake_quant (quant::ConstFakeQuant) quant.const_fake_quant_per_axis (quant::ConstFakeQuantPerAxis) quant.coupled_ref (quant::CoupledRefOp) quant.dcast (quant::DequantizeCastOp) quant.qcast (quant::QuantizeCastOp) quant.region (quant::QuantizeRegionOp) quant.return (quant::ReturnOp) quant.stats (quant::StatisticsOp) Type definition UniformQuantizedType Operation definition quant.const_fake_quant (quant::ConstFakeQuant) Simulates the effect of uniform quantization with const range.
Description: Given a const min, max, num_bits and narrow_range attribute, applies the same uniform quantization simulation as is done by the TensorFlow fake_quant_with_min_max_args op. See the fakeQuantAttrsToType() utility method and the quant-convert-simulated-quantization pass for futher details.</description></item><item><title>Dialect 'rocdl' definition</title><link>https://mlir.llvm.org/docs/Dialects/ROCDLOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ROCDLOps/</guid><description>Operation definition rocdl.workgroup.dim.x (ROCDL::BlockDimXOp) rocdl.workgroup.dim.y (ROCDL::BlockDimYOp) rocdl.workgroup.dim.z (ROCDL::BlockDimZOp) rocdl.workgroup.id.x (ROCDL::BlockIdXOp) rocdl.workgroup.id.y (ROCDL::BlockIdYOp) rocdl.workgroup.id.z (ROCDL::BlockIdZOp) rocdl.grid.dim.x (ROCDL::GridDimXOp) rocdl.grid.dim.y (ROCDL::GridDimYOp) rocdl.grid.dim.z (ROCDL::GridDimZOp) rocdl.workitem.id.x (ROCDL::ThreadIdXOp) rocdl.workitem.id.y (ROCDL::ThreadIdYOp) rocdl.workitem.id.z (ROCDL::ThreadIdZOp) Operation definition rocdl.workgroup.dim.x (ROCDL::BlockDimXOp) Description: Operands: Attributes: Results: res: LLVM dialect type rocdl.workgroup.dim.y (ROCDL::BlockDimYOp) Description: Operands: Attributes: Results: res: LLVM dialect type rocdl.workgroup.dim.z (ROCDL::BlockDimZOp) Description: Operands: Attributes: Results: res: LLVM dialect type rocdl.</description></item><item><title>Dialect 'spv' definition</title><link>https://mlir.llvm.org/docs/Dialects/SPIRVOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SPIRVOps/</guid><description>The SPIR-V dialect in MLIR.
SPIR-V is a binary intermediate language for representing graphical-shader stages and compute kernels for multiple Khronos APIs, including OpenCL, OpenGL, and Vulkan. See https://www.khronos.org/registry/spir-v for more details regarding SPIR-V itself.
The SPIR-V dialect aims to be a proper compiler intermediate representation to facilitate transformations. Ops in this dialect stay at the same semantic level as the SPIR-V specification and try to have one-to-one mapping to the corresponding SPIR-V instructions; but they may deviate representationally to utilize MLIR mechanisms if it results in better representation and thus benefits transformations.</description></item><item><title>Dialect 'vector' definition</title><link>https://mlir.llvm.org/docs/Dialects/VectorOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/VectorOps/</guid><description>Operation definition vector.broadcast (vector::BroadcastOp) vector.constant_mask (vector::ConstantMaskOp) vector.contract (vector::ContractionOp) vector.create_mask (vector::CreateMaskOp) vector.extractelement (vector::ExtractElementOp) vector.extract (vector::ExtractOp) vector.extract_slices (vector::ExtractSlicesOp) vector.fma (vector::FMAOp) vector.insertelement (vector::InsertElementOp) vector.insert (vector::InsertOp) vector.insert_slices (vector::InsertSlicesOp) vector.insert_strided_slice (vector::InsertStridedSliceOp) vector.matrix_multiply (vector::MatmulOp) vector.outerproduct (vector::OuterProductOp) vector.print (vector::PrintOp) vector.reduction (vector::ReductionOp) vector.reshape (vector::ReshapeOp) vector.shape_cast (vector::ShapeCastOp) vector.shuffle (vector::ShuffleOp) vector.strided_slice (vector::StridedSliceOp) vector.transfer_read (vector::TransferReadOp) vector.transfer_write (vector::TransferWriteOp) vector.transpose (vector::TransposeOp) vector.tuple_get (vector::TupleGetOp) vector.tuple (vector::TupleOp) vector.type_cast (vector::TypeCastOp) Operation definition vector.broadcast (vector::BroadcastOp) broadcast operation
Description: Broadcasts the scalar or k-D vector value in the source operand to a n-D result vector such that the broadcast makes sense, i.</description></item><item><title>Dialect Conversion</title><link>https://mlir.llvm.org/docs/DialectConversion/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DialectConversion/</guid><description>This document describes a framework in MLIR in which to perform operation conversions between, and within dialects. This framework allows for transforming illegal operations to those supported by a provided conversion target, via a set of pattern-based operation rewriting patterns.
Modes of Conversion Conversion Target Recursive Legality Rewrite Pattern Specification Restrictions Type Conversion Type Converter Conversion Patterns Region Signature Conversion To utilize the framework, a few things must be provided:</description></item><item><title>GPU Dialect</title><link>https://mlir.llvm.org/docs/Dialects/GPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/GPU/</guid><description>Note: this dialect is more likely to change than others in the near future; use with caution.
This dialect provides middle-level abstractions for launching GPU kernels following a programming model similar to that of CUDA or OpenCL. It provides abstractions for kernel invocations (and may eventually provide those for device management) that are not present at the lower level (e.g., as LLVM IR intrinsics for GPUs). Its goal is to abstract away device- and driver-specific manipulations to launch a GPU kernel and provide a simple path towards GPU execution from MLIR.</description></item><item><title>Introduction and Usage Guide to MLIR's Diagnostics Infrastructure</title><link>https://mlir.llvm.org/docs/Diagnostics/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Diagnostics/</guid><description>Source Locations CallSite Location FileLineCol Location Fused Location Name Location Opaque Location Unknown Location Diagnostic Engine Constructing a Diagnostic Diagnostic Appending arguments Attaching notes InFlight Diagnostic Diagnostic Configuration Options Print Operation On Diagnostic Print StackTrace On Diagnostic Common Diagnostic Handlers Scoped Diagnostic Handler SourceMgr Diagnostic Handler SourceMgr Diagnostic Verifier Handler Parallel Diagnostic Handler This document presents an introduction to using and interfacing with MLIR&amp;rsquo;s diagnostics infrastructure.</description></item><item><title>Introduction to MLIR Interfaces</title><link>https://mlir.llvm.org/docs/Interfaces/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Interfaces/</guid><description>MLIR is generic and very extensible; it allows for opaquely representing many different dialects that have their own operations, attributes, types, and so on. This allows for dialects to be very expressive in their semantics and for MLIR to capture many different levels of abstraction. The downside to this is that transformations and analyses must be extremely conservative about the operations that they encounter, and must special-case the different dialects that they support.</description></item><item><title>Introduction to MLIR Operation Traits</title><link>https://mlir.llvm.org/docs/Traits/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Traits/</guid><description>Defining a Trait Parametric Traits Attaching a Trait Using a Trait Trait List Broadcastable Commutative Function-Like HasParent IsolatedFromAbove Single Block with Implicit Terminator Symbol SymbolTable Terminator MLIR allows for a truly open operation ecosystem, as any dialect may define operations that suit a specific level of abstraction. Traits are a mechanism in which to abstract implementation details and properties that are common across many different operations.</description></item><item><title>Linalg Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Linalg/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Linalg/</guid><description>Rationale Set of Key Transformations High-Level Description of Linalg Ops Payload-Carrying Ops Data Representation: Views Metadata Ops Named Payload-Carrying Ops Open Issues and Design Alternatives Rationale Linalg is designed to solve the High-level Hierarchical Optimization (HHO box) in MLIR and to interoperate nicely within a Mixture Of Expert Compilers environment (i.e. the CGSel box).
The Rationale Document goes into significantly more design and architectural decision details.</description></item><item><title>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</title><link>https://mlir.llvm.org/docs/RationaleLinalgDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/RationaleLinalgDialect/</guid><description>Introduction Positioning Inception Evolution Prior Art Lessons from ONNX Lessons from LIFT Lessons from XLA Lessons from Halide and TVM Lessons from Tensor Comprehensions Lessons from Polyhedral compilers Lessons from the Affine dialect Core Guiding Principles Transformations and Simplicity First Preservation of Information Composable and Declarative Transformations Suitability for Search and Machine Learning Extensibility and Future-Proofness Key Observations Algorithms + Data Structures = Programs The Dialect Need not be Closed Under Transformations Summary of Existing Alternatives a Picture Introduction Positioning This document describes the key design principles that led to the existing implementation of Linalg and aims at exposing the tradeoffs involved when building higher-level Intermediate Representations (IR) and Dialects to facilitate code generation.</description></item><item><title>LLVM IR Dialect</title><link>https://mlir.llvm.org/docs/Dialects/LLVM/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/LLVM/</guid><description>This dialect wraps the LLVM IR types and instructions into MLIR types and operations. It provides several additional operations that are necessary to cover for the differences in the IR structure (e.g., MLIR does not have phi operations and LLVM IR does not have a constant operation).
In this document, we use &amp;ldquo;LLVM IR&amp;rdquo; to designate the intermediate representation of LLVM and &amp;ldquo;LLVM IR dialect&amp;rdquo; to refer to the MLIR dialect reflecting LLVM instructions and types.</description></item><item><title>MLIR Generic DAG Rewriter Infrastructure</title><link>https://mlir.llvm.org/docs/GenericDAGRewriter/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/GenericDAGRewriter/</guid><description>Introduction and Motivation The goal of a compiler IR is to represent code - at various levels of abstraction which pose different sets of tradeoffs in terms of representational capabilities and ease of transformation. However, the ability to represent code is not itself very useful - you also need to be able to implement those transformations.
There are many different sorts of compiler transformations, but this document focuses on a particularly important class of transformation that comes up repeatedly at scale, and is important for the immediate goals of MLIR: that of pattern matching on a set of operations and replacing with another set.</description></item><item><title>MLIR Passes</title><link>https://mlir.llvm.org/docs/Passes/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Passes/</guid><description>This document describes the available MLIR passes and their contracts.
Affine control lowering (-lower-affine) Input invariant Output IR Invariants Conversion from Standard to LLVM IR dialect (-convert-std-to-llvm) Input invariant Output IR Data Copy DMA generation (-affine-data-copy-generate) Loop tiling (-affine-loop-tile) Loop unroll (-affine-loop-unroll) Loop unroll and jam (-affine-loop-unroll-jam) Loop fusion (-affine-loop-fusion) Memref bound checking (-memref-bound-check) Memref dataflow optimization (-memref-dataflow-opt) Memref dependence analysis (-memref-dependence-check) Pipeline data transfer (-affine-pipeline-data-transfer) Affine control lowering (-lower-affine) Convert operations related to affine control into a graph of blocks using operations from the standard dialect.</description></item><item><title>MLIR Quantization</title><link>https://mlir.llvm.org/docs/Quantization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Quantization/</guid><description>This document outlines the design of the MLIR quantization system. While the term &amp;ldquo;quantization&amp;rdquo; is highly overloaded, in this case, it refers to a fairly narrow scope of techniques in use to enable conversion of floating-point computations to corresponding and plausible variants expressed in integer math for inference, as has historically been supported by low-bit depth inference engines such as TFLite, various accelerator hardware, and many DSPs.
Much of this is inspired by the approach taken in this paper with many extensions and adaptations folded in.</description></item><item><title>MLIR Rationale</title><link>https://mlir.llvm.org/docs/Rationale/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/</guid><description>This document is intended to capture some of the alternatives considered and open debates in the design of MLIR, along with the rationale for certain decisions we made. This is not intended to be a &amp;ldquo;finely groomed&amp;rdquo; document - we prefer the ability to dump in interesting tidbits without worrying too much about their consistency or readability.
Abstract Introduction and Motivation Design Decisions Loads and stores Symbols and types Block Arguments vs PHI nodes Index type disallowed in vector/tensor/memref types Bit width of a non-primitive types and index is undefined Integer signedness semantics Splitting floating point vs integer operations Specifying sign in integer comparison operations Specifying comparison kind as attribute &amp;lsquo;select&amp;rsquo; operation to implement min/max Regions Quantized integer operations Dialect type extensions Tuple types Assembly forms Examples Non-affine control flow Non-affine loop bounds Reference 2D Convolution Design alternatives and extensions Polyhedral code representation alternatives: schedule lists vs schedules trees vs affine loop/if forms Affine Relations Regions Read/Write/May_Read/May_Write sets for External Functions Memref Extensions affine.</description></item><item><title>MLIR Specification</title><link>https://mlir.llvm.org/docs/LangRef/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/LangRef/</guid><description>MLIR (Multi-Level IR) is a compiler intermediate representation with similarities to traditional three-address SSA representations (like LLVM IR or SIL ), but which introduces notions from polyhedral loop optimization as first-class concepts. This hybrid design is optimized to represent, analyze, and transform high level dataflow graphs as well as target-specific code generated for high performance data parallel systems. Beyond its representational capabilities, its single continuous design provides a framework to lower from dataflow graphs to high-performance target-specific code.</description></item><item><title>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</title><link>https://mlir.llvm.org/docs/MLIRForGraphAlgorithms/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/MLIRForGraphAlgorithms/</guid><description>The existing documentation about MLIR focuses on long term vision, how its pieces fit together, and the benefits of modular and composable infrastructure in the vast and distant future. While this viewpoint appeals to some, it causes concern for others who are more concerned about the &amp;ldquo;here and now&amp;rdquo; - why does it make sense to make a &amp;ldquo;revolutionary&amp;rdquo; change when any individual problem can be fixed in place?
This document explains that adoption of MLIR to solve graph based problems isn&amp;rsquo;t a revolutionary change: it is an incremental series of steps which build on each other, each of which delivers local value.</description></item><item><title>MLIR: The case for a simplified polyhedral form</title><link>https://mlir.llvm.org/docs/RationaleSimplifiedPolyhedralForm/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/RationaleSimplifiedPolyhedralForm/</guid><description>MLIR embraces polyhedral compiler techniques for their many advantages representing and transforming dense numerical kernels, but it uses a form that differs significantly from other polyhedral frameworks.
Disclaimer / Warning
This document is a very early design proposal (which has since been accepted) that explored the tradeoffs of using this simplified form vs the traditional polyhedral schedule list form. At some point, this document could be dusted off and written as a proper academic paper, but until now, it is better to included it in this crafty form than not to.</description></item><item><title>Operation Canonicalization in MLIR</title><link>https://mlir.llvm.org/docs/Canonicalization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Canonicalization/</guid><description>Canonicalization is an important part of compiler IR design: it makes it easier to implement reliable compiler transformations and to reason about what is better or worse in the code, and it forces interesting discussions about the goals of a particular level of IR. Dan Gohman wrote an article exploring these issues; it is worth reading if you&amp;rsquo;re not familiar with these concepts.
Most compilers have canonicalization passes, and sometimes they have many different ones (e.</description></item><item><title>Quickstart tutorial to adding MLIR graph rewrite</title><link>https://mlir.llvm.org/docs/QuickstartRewrites/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/QuickstartRewrites/</guid><description>This document will present a quickstart to adding graph rewrites. We shall start by defining an operation, showing multiple ways to define the rewrite using patterns, as well as defining the rewrite using a graph walker (note: using patterns and the rewrite engine is preferred, showing the walker is for demonstration purposes).
See MLIR specification for more information about MLIR, the structure of the IR, operations, etc. See Table-driven Operation Definition and Declarative Rewrite Rule for the detailed explanation of all available mechanisms for defining operations and rewrites in a table-driven manner.</description></item><item><title>Quickstart tutorial to defining custom dialect attributes and types</title><link>https://mlir.llvm.org/docs/DefiningAttributesAndTypes/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DefiningAttributesAndTypes/</guid><description>This document is a quickstart to defining dialect specific extensions to the attribute and type system . The main part of the tutorial focuses on defining types, but the instructions are nearly identical for defining attributes.
See MLIR specification for more information about MLIR, the structure of the IR, operations, etc.
Types Types in MLIR (like attributes, locations, and many other things) are value-typed. This means that instances of Type should be passed around by-value, as opposed to by-pointer or by-reference.</description></item><item><title>Shape inference</title><link>https://mlir.llvm.org/docs/ShapeInference/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/ShapeInference/</guid><description>Shape inference as discussed here is considered a specific instance of type inference for ShapedType . Type constraints are along (at least) three axis: 1) elemental type, 2) rank (including static or dynamic), 3) dimensions. While some operations have no compile time fixed shape (e.g., output shape is dictated by data) we could still have some knowledge of constraints/bounds in the system for that operation (e.g., the output of a tf.</description></item><item><title>SPIR-V Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SPIR-V/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SPIR-V/</guid><description>This document describes the design of the SPIR-V dialect in MLIR. It lists various design choices we made for modeling different SPIR-V mechanisms, and their rationale.
This document also explains in a high-level manner how different components are organized and implemented in the code and gives steps to follow for extending them.
This document assumes familiarity with SPIR-V. SPIR-V is the Khronos Group’s binary intermediate language for representing graphics shaders and compute kernels.</description></item><item><title>Standard Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Standard/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Standard/</guid><description>This dialect provides documentation for operations within the Standard dialect.
Note: This dialect is a collection of operations for several different concepts, and should be split into multiple more-focused dialects accordingly.
Terminator operations &amp;lsquo;br&amp;rsquo; terminator operation &amp;lsquo;cond_br&amp;rsquo; terminator operation &amp;lsquo;return&amp;rsquo; terminator operation Core Operations &amp;lsquo;call&amp;rsquo; operation &amp;lsquo;call_indirect&amp;rsquo; operation &amp;lsquo;dim&amp;rsquo; operation Memory Operations &amp;lsquo;alloc&amp;rsquo; operation &amp;lsquo;alloc_static&amp;rsquo; operation &amp;lsquo;dealloc&amp;rsquo; operation &amp;lsquo;dma_start&amp;rsquo; operation &amp;lsquo;dma_wait&amp;rsquo; operation &amp;lsquo;extract_element&amp;rsquo; operation &amp;lsquo;load&amp;rsquo; operation &amp;lsquo;splat&amp;rsquo; operation &amp;lsquo;store&amp;rsquo; operation &amp;lsquo;tensor_load&amp;rsquo; operation &amp;lsquo;tensor_store&amp;rsquo; operation Unary Operations &amp;lsquo;absf&amp;rsquo; operation &amp;lsquo;ceilf&amp;rsquo; operation &amp;lsquo;cos&amp;rsquo; operation &amp;lsquo;exp&amp;rsquo; operation &amp;lsquo;negf&amp;rsquo; operation &amp;lsquo;sqrt&amp;rsquo; operation &amp;lsquo;tanh&amp;rsquo; operation Arithmetic Operations &amp;lsquo;addi&amp;rsquo; operation &amp;lsquo;addf&amp;rsquo; operation &amp;lsquo;and&amp;rsquo; operation &amp;lsquo;cmpi&amp;rsquo; operation &amp;lsquo;constant&amp;rsquo; operation &amp;lsquo;copysign&amp;rsquo; operation &amp;lsquo;divis&amp;rsquo; operation &amp;lsquo;diviu&amp;rsquo; operation &amp;lsquo;memref_cast&amp;rsquo; operation &amp;lsquo;mulf&amp;rsquo; operation &amp;lsquo;or&amp;rsquo; operation &amp;lsquo;remis&amp;rsquo; operation &amp;lsquo;remiu&amp;rsquo; operation &amp;lsquo;select&amp;rsquo; operation &amp;lsquo;tensor_cast&amp;rsquo; operation &amp;lsquo;xor&amp;rsquo; operation TODO: shape, which returns a 1D tensor, and can take an unknown rank tensor as input.</description></item><item><title>Symbols and Symbol Tables</title><link>https://mlir.llvm.org/docs/SymbolsAndSymbolTables/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/SymbolsAndSymbolTables/</guid><description>Symbol Defining a Symbol Symbol Table Referencing a Symbol Manipulating a Symbol Symbol Visibility With Regions , the multi-level aspect of MLIR is structural in the IR. A lot of infrastructure within the compiler is built around this nesting structure; including the processing of operations within the pass manager . One advantage of the MLIR design is that it is able to process operations in parallel, utilizing multiple threads.</description></item><item><title>Table-driven Declarative Rewrite Rule (DRR)</title><link>https://mlir.llvm.org/docs/DeclarativeRewrites/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DeclarativeRewrites/</guid><description>In addition to subclassing the mlir::RewritePattern C++ class, MLIR also supports defining rewrite rules in a declarative manner. Similar to Op Definition Specification (ODS), this is achieved via TableGen , which is a language to maintain records of domain-specific information. The rewrite rules are specified concisely in a TableGen record, which will be expanded into an equivalent mlir::RewritePattern subclass at compiler build time.
This manual explains in detail all of the available mechanisms for defining rewrite rules in such a declarative manner.</description></item><item><title>Table-driven Operation Definition Specification (ODS)</title><link>https://mlir.llvm.org/docs/OpDefinitions/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/OpDefinitions/</guid><description>In addition to specializing the mlir::Op C++ template, MLIR also supports defining operations in a table-driven manner. This is achieved via TableGen , which is both a generic language and its tooling to maintain records of domain-specific information. Facts regarding an operation are specified concisely into a TableGen record, which will be expanded into an equivalent mlir::Op C++ template specialization at compiler build time.
This manual explains in detail all the available mechanisms for defining operations in such a table-driven manner.</description></item><item><title>Usage of 'Const' in MLIR, for core IR types</title><link>https://mlir.llvm.org/docs/UsageOfConst/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/UsageOfConst/</guid><description>aka, where&amp;rsquo;d const go?
The MLIR data structures that represent the IR itself (Instruction, Block, etc) form a graph-based data structure, and the compiler analyses and passes frequently walk this graph (e.g. traversing from defs to users). The early design of MLIR adopted the const model of LLVM, which is familiar and well understood (even though the LLVM implementation is flawed in many ways).
The design team since decided to change to a different module, which eschews const entirely for the core IR types: you should never see a const method on Operation, should never see the type const Value, and you shouldn&amp;rsquo;t feel bad about this.</description></item><item><title>Vector Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Vector/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Vector/</guid><description>MLIR supports multi-dimensional vector types and custom operations on those types. A generic, retargetable, higher-order vector type (n-D with n &amp;gt; 1) is a structured type, that carries semantic information useful for transformations. This document discusses retargetable abstractions that exist in MLIR today and operate on ssa-values of type vector along with pattern rewrites and lowerings that enable targeting specific instructions on concrete targets. These abstractions serve to separate concerns between operations on memref (a.</description></item><item><title>Writing a Pass</title><link>https://mlir.llvm.org/docs/WritingAPass/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/WritingAPass/</guid><description>Operation Pass OperationPass : Op-Specific OperationPass : Op-Agnostic Analysis Management Querying Analyses Preserving Analyses Pass Failure Pass Manager OpPassManager Pass Registration Pass Pipeline Registration Textual Pass Pipeline Specification Instance Specific Pass Options Pass Statistics Pass Instrumentation Standard Instrumentations Crash and Failure Reproduction Passes represent the basic infrastructure for transformation and optimization. This document provides a quickstart to the pass infrastructure in MLIR and how to use it.</description></item></channel></rss>