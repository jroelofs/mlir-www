<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>MLIR Passes - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.64.1"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Passes/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/llvm-project/mlir>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/master/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/master/mlir>GitHub</a></li></ul></li><li><a href="https://bugs.llvm.org/buglist.cgi?bug_status=__open__&list_id=177877&order=changeddate%20DESC%2Cpriority%2Cbug_severity&product=MLIR&query_format=specific">Bugs</a></li></ul></nav></div><div class=content-container><main><h1>MLIR Passes</h1><p>This document describes the available MLIR passes and their contracts.</p><p><nav id=TableOfContents><ul><li><a href=#affine-control-lowering--lower-affine>Affine control lowering (-lower-affine)</a><ul><li><a href=#input-invariant>Input invariant</a></li><li><a href=#output-ir>Output IR</a></li><li><a href=#invariants>Invariants</a></li></ul></li><li><a href=#conversion-from-standard-to-llvm-ir-dialect--convert-std-to-llvm>Conversion from Standard to LLVM IR dialect (-convert-std-to-llvm)</a><ul><li><a href=#input-invariant-1>Input invariant</a></li><li><a href=#output-ir-1>Output IR</a></li></ul></li><li><a href=#data-copy-dma-generation--affine-data-copy-generate>Data Copy DMA generation (-affine-data-copy-generate)</a></li><li><a href=#loop-tiling--affine-loop-tile>Loop tiling (-affine-loop-tile)</a></li><li><a href=#loop-unroll--affine-loop-unroll>Loop unroll (-affine-loop-unroll)</a></li><li><a href=#loop-unroll-and-jam--affine-loop-unroll-jam>Loop unroll and jam (-affine-loop-unroll-jam)</a></li><li><a href=#loop-fusion--affine-loop-fusion>Loop fusion (-affine-loop-fusion)</a></li><li><a href=#memref-bound-checking--memref-bound-check>Memref bound checking (-memref-bound-check)</a></li><li><a href=#memref-dataflow-optimization--memref-dataflow-opt>Memref dataflow optimization (-memref-dataflow-opt)</a></li><li><a href=#memref-dependence-analysis--memref-dependence-check>Memref dependence analysis (-memref-dependence-check)</a></li><li><a href=#pipeline-data-transfer--affine-pipeline-data-transfer>Pipeline data transfer (-affine-pipeline-data-transfer)</a></li></ul></nav><h2 id=affine-control-lowering--lower-affine>Affine control lowering (<code>-lower-affine</code>)</h2><p>Convert operations related to affine control into a graph of blocks using
operations from the standard dialect.</p><p>Loop statements are converted to a subgraph of blocks (initialization, condition
checking, subgraph of body blocks) with loop induction variable being passed as
the block argument of the condition checking block. Conditional statements are
converted to a subgraph of blocks (chain of condition checking with
short-circuit logic, subgraphs of &lsquo;then&rsquo; and &lsquo;else&rsquo; body blocks). <code>affine.apply</code>
operations are converted into sequences of primitive arithmetic operations that
have the same effect, using operands of the <code>index</code> type. Consequently, named
maps and sets may be removed from the module.</p><p>For example, <code>%r = affine.apply (d0, d1)[s0] -> (d0 + 2*d1 + s0)(%d0, %d1)[%s0]</code>
can be converted into:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%d0</span> <span class=p>=</span> <span class=p>&lt;</span><span class=p>.</span><span class=p>.</span><span class=p>.</span><span class=p>&gt;</span>
<span class=nv>%d1</span> <span class=p>=</span> <span class=p>&lt;</span><span class=p>.</span><span class=p>.</span><span class=p>.</span><span class=p>&gt;</span>
<span class=nv>%s0</span> <span class=p>=</span> <span class=p>&lt;</span><span class=p>.</span><span class=p>.</span><span class=p>.</span><span class=p>&gt;</span>
<span class=nv>%0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>2</span> <span class=p>:</span> <span class=k>index</span>
<span class=nv>%1</span> <span class=p>=</span> muli <span class=nv>%0</span><span class=p>,</span> <span class=nv>%d1</span>
<span class=nv>%2</span> <span class=p>=</span> addi <span class=nv>%d0</span><span class=p>,</span> <span class=nv>%1</span>
<span class=nv>%r</span> <span class=p>=</span> addi <span class=nv>%2</span><span class=p>,</span> <span class=nv>%s0</span>
</code></pre></div><h3 id=input-invariant>Input invariant</h3><ul><li>no <code>Tensor</code> types;</li></ul><p>These restrictions may be lifted in the future.</p><h3 id=output-ir>Output IR</h3><p>Functions with <code>affine.for</code> and <code>affine.if</code> operations eliminated. These
functions may contain operations from the Standard dialect in addition to those
already present before the pass.</p><h3 id=invariants>Invariants</h3><ul><li>Functions without a body are not modified.</li><li>The semantics of the other functions is preserved.</li><li>Individual operations other than those mentioned above are not modified if
they do not depend on the loop iterator value or on the result of
<code>affine.apply</code>.</li></ul><h2 id=conversion-from-standard-to-llvm-ir-dialect--convert-std-to-llvm>Conversion from Standard to LLVM IR dialect (<code>-convert-std-to-llvm</code>)</h2><p>Convert standard operations into the LLVM IR dialect operations.</p><h3 id=input-invariant-1>Input invariant</h3><ul><li>operations including: arithmetic on integers and floats, constants, direct
calls, returns and branches;</li><li>no <code>tensor</code> types;</li><li>all <code>vector</code> are one-dimensional;</li><li>all blocks are reachable by following the successors of the first basic
block;</li></ul><p>If other operations are present and their results are required by the LLVM IR
dialect operations, the pass will fail. Any LLVM IR operations or types already
present in the IR will be kept as is.</p><h3 id=output-ir-1>Output IR</h3><p>Functions converted to LLVM IR. Function arguments types are converted
one-to-one. Function results are converted one-to-one and, in case more than 1
value is returned, packed into an LLVM IR struct type. Function calls and
returns are updated accordingly. Block argument types are updated to use LLVM IR
types.</p><h2 id=data-copy-dma-generation--affine-data-copy-generate>Data Copy DMA generation (<code>-affine-data-copy-generate</code>)</h2><p>Replaces all loads and stores on memref&rsquo;s living in &lsquo;slowMemorySpace&rsquo; by
introducing DMA operations (strided DMA if necessary) to transfer data to/from
<code>fastMemorySpace</code> and rewriting the original load&rsquo;s/store&rsquo;s to instead
load/store from the allocated fast memory buffers. Additional options specify
the identifier corresponding to the fast memory space and the amount of fast
memory space available. The pass traverses through the nesting structure,
recursing to inner levels if necessary to determine at what depth DMA transfers
need to be placed so that the allocated buffers fit within the memory capacity
provided. If this is not possible (for example, when the elemental type itself
is of size larger than the DMA capacity), an error with location information is
emitted. The DMA transfers are also hoisted up past all loops with respect to
which the transfers are invariant.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@loop_nest_tiled</span><span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x1024x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>{</span>
  <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x1024x</span><span class=k>f32</span><span class=p>&gt;</span>
  affine<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>256</span> step <span class=m>32</span> <span class=p>{</span>
    affine<span class=p>.</span>for <span class=nv>%i1</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>1024</span> step <span class=m>32</span> <span class=p>{</span>
      affine<span class=p>.</span>for <span class=nv>%i2</span> <span class=p>=</span> <span class=p>(</span>d0<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0<span class=p>)</span><span class=p>(</span><span class=nv>%i0</span><span class=p>)</span> to <span class=p>(</span>d0<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0 <span class=err>+</span> <span class=m>32</span><span class=p>)</span><span class=p>(</span><span class=nv>%i0</span><span class=p>)</span> <span class=p>{</span>
        affine<span class=p>.</span>for <span class=nv>%i3</span> <span class=p>=</span> <span class=p>(</span>d0<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0<span class=p>)</span><span class=p>(</span><span class=nv>%i1</span><span class=p>)</span> to <span class=p>(</span>d0<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0 <span class=err>+</span> <span class=m>32</span><span class=p>)</span><span class=p>(</span><span class=nv>%i1</span><span class=p>)</span> <span class=p>{</span>
          <span class=nv>%1</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%0</span><span class=p>[</span><span class=nv>%i2</span><span class=p>,</span> <span class=nv>%i3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x1024x</span><span class=k>f32</span><span class=p>&gt;</span>
        <span class=p>}</span>
      <span class=p>}</span>
    <span class=p>}</span>
  <span class=p>}</span>
  <span class=kt>return</span> <span class=nv>%0</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x1024x</span><span class=k>f32</span><span class=p>&gt;</span>
<span class=p>}</span>
</code></pre></div><p>Output (with flags: -affine-data-copy-generate -affine-data-copy-generate-fast-mem-space=2)</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>module <span class=p>{</span>
  <span class=kt>func</span> <span class=nf>@loop_nest_tiled</span><span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x1024x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>{</span>
    <span class=nv>%c262144</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>262144</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%c0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x1024x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%1</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x1024x</span><span class=k>f32</span><span class=p>,</span> <span class=m>2</span><span class=p>&gt;</span>
    <span class=nv>%2</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>i32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%c0</span><span class=p>,</span> <span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%c0</span><span class=p>,</span> <span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c262144</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x1024x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x1024x</span><span class=k>f32</span><span class=p>,</span> <span class=m>2</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>i32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c262144</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>i32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>for <span class=nv>%arg0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>256</span> step <span class=m>32</span> <span class=p>{</span>
      affine<span class=p>.</span>for <span class=nv>%arg1</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>1024</span> step <span class=m>32</span> <span class=p>{</span>
        affine<span class=p>.</span>for <span class=nv>%arg2</span> <span class=p>=</span> <span class=nv>#map1</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>)</span> to <span class=nv>#map2</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>)</span> <span class=p>{</span>
          affine<span class=p>.</span>for <span class=nv>%arg3</span> <span class=p>=</span> <span class=nv>#map1</span><span class=p>(</span><span class=nv>%arg1</span><span class=p>)</span> to <span class=nv>#map2</span><span class=p>(</span><span class=nv>%arg1</span><span class=p>)</span> <span class=p>{</span>
            <span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%arg2</span><span class=p>,</span> <span class=nv>%arg3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x1024x</span><span class=k>f32</span><span class=p>,</span> <span class=m>2</span><span class=p>&gt;</span>
          <span class=p>}</span>
        <span class=p>}</span>
      <span class=p>}</span>
    <span class=p>}</span>
    dealloc <span class=nv>%2</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>i32</span><span class=p>&gt;</span>
    dealloc <span class=nv>%1</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x1024x</span><span class=k>f32</span><span class=p>,</span> <span class=m>2</span><span class=p>&gt;</span>
    <span class=kt>return</span> <span class=nv>%0</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x1024x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><h2 id=loop-tiling--affine-loop-tile>Loop tiling (<code>-affine-loop-tile</code>)</h2><p>Performs tiling or blocking of loop nests. It currently works on perfect loop
nests.</p><h2 id=loop-unroll--affine-loop-unroll>Loop unroll (<code>-affine-loop-unroll</code>)</h2><p>This pass implements loop unrolling. It is able to unroll loops with arbitrary
bounds, and generate a cleanup loop when necessary.</p><h2 id=loop-unroll-and-jam--affine-loop-unroll-jam>Loop unroll and jam (<code>-affine-loop-unroll-jam</code>)</h2><p>This pass implements unroll and jam for loops. It works on both perfect or
imperfect loop nests.</p><h2 id=loop-fusion--affine-loop-fusion>Loop fusion (<code>-affine-loop-fusion</code>)</h2><p>Performs fusion of loop nests using a slicing-based approach. The fused loop
nests, when possible, are rewritten to access significantly smaller local
buffers instead of the original memref&rsquo;s, and the latter are often
either completely optimized away or contracted. This transformation leads to
enhanced locality and lower memory footprint through the elimination or
contraction of temporaries / intermediate memref&rsquo;s. These benefits are sometimes
achieved at the expense of redundant computation through a cost model that
evaluates available choices such as the depth at which a source slice should be
materialized in the designation slice.</p><h2 id=memref-bound-checking--memref-bound-check>Memref bound checking (<code>-memref-bound-check</code>)</h2><p>Checks all load&rsquo;s and store&rsquo;s on memref&rsquo;s for out of bound accesses, and reports
any out of bound accesses (both overrun and underrun) with location information.</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>test<span class=err>/</span>Transforms<span class=err>/</span><span class=kt>memref</span><span class=err>-</span>bound<span class=err>-</span>check<span class=p>.</span>mlir<span class=p>:</span><span class=m>19</span><span class=p>:</span><span class=m>13</span><span class=p>:</span> error<span class=p>:</span> <span class=err>&#39;</span>load<span class=err>&#39;</span> op <span class=kt>memref</span> out of upper bound access along dimension <span class=nv>#2</span>
      <span class=nv>%x</span>  <span class=p>=</span> load <span class=nv>%A</span><span class=p>[</span><span class=nv>%idx0</span><span class=p>,</span> <span class=nv>%idx1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>9 x</span> <span class=m>9 x</span> <span class=k>i32</span><span class=p>&gt;</span>
            <span class=err>^</span>
test<span class=err>/</span>Transforms<span class=err>/</span><span class=kt>memref</span><span class=err>-</span>bound<span class=err>-</span>check<span class=p>.</span>mlir<span class=p>:</span><span class=m>19</span><span class=p>:</span><span class=m>13</span><span class=p>:</span> error<span class=p>:</span> <span class=err>&#39;</span>load<span class=err>&#39;</span> op <span class=kt>memref</span> out of lower bound access along dimension <span class=nv>#2</span>
      <span class=nv>%x</span>  <span class=p>=</span> load <span class=nv>%A</span><span class=p>[</span><span class=nv>%idx0</span><span class=p>,</span> <span class=nv>%idx1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>9 x</span> <span class=m>9 x</span> <span class=k>i32</span><span class=p>&gt;</span>
            <span class=err>^</span>
</code></pre></div><h2 id=memref-dataflow-optimization--memref-dataflow-opt>Memref dataflow optimization (<code>-memref-dataflow-opt</code>)</h2><p>This pass performs store to load forwarding for memref&rsquo;s to eliminate memory
accesses and potentially the entire memref if all its accesses are forwarded.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@store_load_affine_apply</span><span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>{</span>
  <span class=nv>%cf7</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>7.0</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=nv>%m</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
  affine<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
    affine<span class=p>.</span>for <span class=nv>%i1</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
      affine<span class=p>.</span>store <span class=nv>%cf7</span><span class=p>,</span> <span class=nv>%m</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%v0</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%m</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%v1</span> <span class=p>=</span> addf <span class=nv>%v0</span><span class=p>,</span> <span class=nv>%v0</span> <span class=p>:</span> <span class=k>f32</span>
    <span class=p>}</span>
  <span class=p>}</span>
  <span class=kt>return</span> <span class=nv>%m</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
<span class=p>}</span>
</code></pre></div><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>module <span class=p>{</span>
  <span class=kt>func</span> <span class=nf>@store_load_affine_apply</span><span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>{</span>
    <span class=nv>%cst</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>7.000000e+00</span> <span class=p>:</span> <span class=k>f32</span>
    <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>for <span class=nv>%arg0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
      affine<span class=p>.</span>for <span class=nv>%arg1</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
        affine<span class=p>.</span>store <span class=nv>%cst</span><span class=p>,</span> <span class=nv>%0</span><span class=p>[</span><span class=nv>%arg0</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
        <span class=nv>%1</span> <span class=p>=</span> addf <span class=nv>%cst</span><span class=p>,</span> <span class=nv>%cst</span> <span class=p>:</span> <span class=k>f32</span>
      <span class=p>}</span>
    <span class=p>}</span>
    <span class=kt>return</span> <span class=nv>%0</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=p>}</span>
<span class=p>}</span>

</code></pre></div><h2 id=memref-dependence-analysis--memref-dependence-check>Memref dependence analysis (<code>-memref-dependence-check</code>)</h2><p>This pass performs dependence analysis to determine dependences between pairs of
memory operations (load&rsquo;s and store&rsquo;s) on memref&rsquo;s. Dependence analysis exploits
polyhedral information available (affine maps, expressions, and affine.apply
operations) to precisely represent dependences using affine constraints, while
also computing dependence vectors from them, where each component of the
dependence vector provides a lower and an upper bound on the dependence distance
along the corresponding dimension.</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>test<span class=err>/</span>Transforms<span class=err>/</span><span class=kt>memref</span><span class=err>-</span>dataflow<span class=err>-</span>opt<span class=p>.</span>mlir<span class=p>:</span><span class=m>232</span><span class=p>:</span><span class=m>7</span><span class=p>:</span> note<span class=p>:</span> dependence from <span class=m>2</span> to <span class=m>1</span> at depth <span class=nl>1 =</span> <span class=p>(</span><span class=p>[</span><span class=m>1</span><span class=p>,</span> <span class=m>1</span><span class=p>]</span><span class=p>,</span> <span class=p>[</span><span class=err>-</span>inf<span class=p>,</span> <span class=err>+</span>inf<span class=p>]</span><span class=p>)</span>
      store <span class=nv>%cf9</span><span class=p>,</span> <span class=nv>%m</span><span class=p>[</span><span class=nv>%idx</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span>
</code></pre></div><h2 id=pipeline-data-transfer--affine-pipeline-data-transfer>Pipeline data transfer (<code>-affine-pipeline-data-transfer</code>)</h2><p>This pass performs a transformation to overlap non-blocking DMA operations in a
loop with computations through double buffering. This is achieved by advancing
dma_start operations with respect to other operations.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@pipelinedatatransfer</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span>
  <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=nv>%1</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
  <span class=nv>%2</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=nv>%c0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
  <span class=nv>%c128</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>128</span> <span class=p>:</span> <span class=k>index</span>
  affine<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>8</span> <span class=p>{</span>
    affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=nv>%4</span> <span class=p>=</span> <span class=s>&#34;compute&#34;</span><span class=p>(</span><span class=nv>%3</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
    affine<span class=p>.</span>store <span class=nv>%4</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
  <span class=p>}</span>
  <span class=kt>return</span>
<span class=p>}</span>
</code></pre></div><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>module <span class=p>{</span>
  <span class=kt>func</span> <span class=nf>@pipelinedatatransfer</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span>
    <span class=nv>%c8</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>8</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%c0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%c0_0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%c128</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>128</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%1</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=nv>%2</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%c0</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>for <span class=nv>%arg0</span> <span class=p>=</span> <span class=m>1</span> to <span class=m>8</span> <span class=p>{</span>
      affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%arg0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%arg0</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%arg0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%arg0</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%8</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map3</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>)</span>
      <span class=nv>%9</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%8</span><span class=p>)</span>
      <span class=nv>%10</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%8</span><span class=p>)</span>
      affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%8</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%11</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%8</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%8</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
      <span class=nv>%12</span> <span class=p>=</span> <span class=s>&#34;compute&#34;</span><span class=p>(</span><span class=nv>%11</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
      affine<span class=p>.</span>store <span class=nv>%12</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%8</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%8</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=p>}</span>
    <span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map3</span><span class=p>(</span><span class=nv>%c8</span><span class=p>)</span>
    <span class=nv>%4</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%3</span><span class=p>)</span>
    <span class=nv>%5</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%3</span><span class=p>)</span>
    affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%3</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%6</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%3</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=nv>%7</span> <span class=p>=</span> <span class=s>&#34;compute&#34;</span><span class=p>(</span><span class=nv>%6</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
    affine<span class=p>.</span>store <span class=nv>%7</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%3</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    dealloc <span class=nv>%2</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    dealloc <span class=nv>%1</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=kt>return</span>
  <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=/docs/GenericDAGRewriter/ title="MLIR Generic DAG Rewriter Infrastructure"><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - MLIR Generic DAG Rewriter Infrastructure</a>
<a class="nav nav-next" href=/docs/Quantization/ title="MLIR Quantization">Next - MLIR Quantization <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=/talks/>Talks and Related Publications</a></li><li><a href=/users/>Users of MLIR</a></li><li class=has-sub-menu><a href=/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=/getting_started/Contributing/>How to Contribute</a></li><li><a href=/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=/getting_started/openprojects/>Open Projects</a></li><li><a href=/getting_started/Glossary/>Glossary</a></li><li><a href=/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=/docs/Dialects/>Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Dialects/Affine/>Affine Dialect</a></li><li><a href=/docs/Dialects/AffineOps/>Dialect 'affine' definition</a></li><li><a href=/docs/Dialects/AVX512/>Dialect 'avx512' definition</a></li><li><a href=/docs/Dialects/FxpMathOps/>Dialect 'fxpmath' definition</a></li><li><a href=/docs/Dialects/GPUOps/>Dialect 'gpu' definition</a></li><li><a href=/docs/Dialects/LinalgDoc/>Dialect 'linalg' definition</a></li><li><a href=/docs/Dialects/LLVMAVX512/>Dialect 'llvm_avx512' definition</a></li><li><a href=/docs/Dialects/LoopOps/>Dialect 'loop' definition</a></li><li><a href=/docs/Dialects/NVVMOps/>Dialect 'nvvm' definition</a></li><li><a href=/docs/Dialects/OpenMPOps/>Dialect 'omp' definition</a></li><li><a href=/docs/Dialects/QuantOps/>Dialect 'quant' definition</a></li><li><a href=/docs/Dialects/ROCDLOps/>Dialect 'rocdl' definition</a></li><li><a href=/docs/Dialects/SPIRVOps/>Dialect 'spv' definition</a></li><li><a href=/docs/Dialects/VectorOps/>Dialect 'vector' definition</a></li><li><a href=/docs/Dialects/GPU/>GPU Dialect</a></li><li><a href=/docs/Dialects/Linalg/>Linalg Dialect</a></li><li><a href=/docs/Dialects/LLVM/>LLVM IR Dialect</a></li><li><a href=/docs/Dialects/SPIR-V/>SPIR-V Dialect</a></li><li><a href=/docs/Dialects/Standard/>Standard Dialect</a></li><li><a href=/docs/Dialects/Vector/>Vector Dialect</a></li></ul></li><li class=has-sub-menu><a href=/docs/Tutorials/Toy/>Toy<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Tutorial Introduction</a></li><li><a href=/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li><a href=/docs/EDSC/>Background: declarative builders API</a></li><li><a href=/docs/ConversionToLLVMDialect/>Conversion to the LLVM Dialect</a></li><li><a href=/docs/CreatingADialect/>Creating a Dialect</a></li><li><a href=/docs/DialectConversion/>Dialect Conversion</a></li><li><a href=/docs/Diagnostics/>Introduction and Usage Guide to MLIR's Diagnostics Infrastructure</a></li><li><a href=/docs/Interfaces/>Introduction to MLIR Interfaces</a></li><li><a href=/docs/Traits/>Introduction to MLIR Operation Traits</a></li><li><a href=/docs/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=/docs/GenericDAGRewriter/>MLIR Generic DAG Rewriter Infrastructure</a></li><li class=active><a href=/docs/Passes/>MLIR Passes</a></li><li><a href=/docs/Quantization/>MLIR Quantization</a></li><li><a href=/docs/Rationale/>MLIR Rationale</a></li><li><a href=/docs/LangRef/>MLIR Specification</a></li><li><a href=/docs/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=/docs/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=/docs/Canonicalization/>Operation Canonicalization in MLIR</a></li><li><a href=/docs/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li><a href=/docs/DefiningAttributesAndTypes/>Quickstart tutorial to defining custom dialect attributes and types</a></li><li><a href=/docs/ShapeInference/>Shape inference</a></li><li><a href=/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=/docs/OpDefinitions/>Table-driven Operation Definition Specification (ODS)</a></li><li><a href=/docs/UsageOfConst/>Usage of 'Const' in MLIR, for core IR types</a></li><li><a href=/docs/WritingAPass/>Writing a Pass</a></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>