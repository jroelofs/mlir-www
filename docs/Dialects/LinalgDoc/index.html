<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Dialect 'linalg' definition - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.64.1"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Dialects/LinalgDoc/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/llvm-project/mlir>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/master/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/master/mlir>GitHub</a></li></ul></li><li><a href="https://bugs.llvm.org/buglist.cgi?bug_status=__open__&list_id=177877&order=changeddate%20DESC%2Cpriority%2Cbug_severity&product=MLIR&query_format=specific">Bugs</a></li></ul></nav></div><div class=content-container><main><h1>Dialect 'linalg' definition</h1><p>The <code>linalg</code> dialect groups together a set of types, operations and
transformations that are useful to implement a structured abstraction on
buffers and tensors. These abstractions are useful for transformations and
can lower to scalar load/store and other operations or to more general
library calls.</p><p>Additional
<a href=https://mlir.llvm.org/docs/Dialects/Linalg>Linalg Dialect
Documentation</a>
and a
<a href=https://mlir.llvm.org/docs/RationaleLinalgDialect>Rationale Document</a>
are
are also available and should be read first before going in the details of
the op semantics.</p><p><nav id=TableOfContents><ul><li><a href=#type-definition>Type definition</a><ul><li><a href=#range>range</a></li></ul></li><li><a href=#operation-definition>Operation definition</a><ul><li><a href=#linalgconv-linalgconvop>linalg.conv (linalg::ConvOp)</a></li><li><a href=#linalgcopy-linalgcopyop>linalg.copy (linalg::CopyOp)</a></li><li><a href=#linalgdot-linalgdotop>linalg.dot (linalg::DotOp)</a></li><li><a href=#linalgfill-linalgfillop>linalg.fill (linalg::FillOp)</a></li><li><a href=#linalggeneric-linalggenericop>linalg.generic (linalg::GenericOp)</a></li><li><a href=#linalgindexed_generic-linalgindexedgenericop>linalg.indexed_generic (linalg::IndexedGenericOp)</a></li><li><a href=#linalgrange-linalgrangeop>linalg.range (linalg::RangeOp)</a></li><li><a href=#linalgreshape-linalgreshapeop>linalg.reshape (linalg::ReshapeOp)</a></li><li><a href=#linalgslice-linalgsliceop>linalg.slice (linalg::SliceOp)</a></li><li><a href=#linalgtranspose-linalgtransposeop>linalg.transpose (linalg::TransposeOp)</a></li><li><a href=#linalgyield-linalgyieldop>linalg.yield (linalg::YieldOp)</a></li><li><a href=#linalgmatmul-linalgmatmulop>linalg.matmul (linalg::MatmulOp)</a></li><li><a href=#linalgmatvec-linalgmatvecop>linalg.matvec (linalg::MatvecOp)</a></li></ul></li></ul></nav><h2 id=type-definition>Type definition</h2><h3 id=range>range</h3><h2 id=operation-definition>Operation definition</h2><h3 id=linalgconv-linalgconvop>linalg.conv (linalg::ConvOp)</h3><h4 id=description>Description:</h4><p>Generic n-D convolution as described in the TF documentation:
<a href=https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/convolution>https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/nn/convolution</a></p><pre><code>  output[b, x[0], ..., x[N-1], k] =
  sum_{z[0], ..., z[N-1], q}
      filter[z[0], ..., z[N-1], q, k] *
      padded_input[b,
                   x[0] * strides[0] + dilation_rate[0] * z[0],
                   ...,
                   x[N-1] * strides[N-1] + dilation_rate[N-1] * z[N-1],
                   q]
</code></pre><h4 id=operands>Operands:</h4><ol><li><code>filter</code>: strided memref of any type values</li><li><code>input</code>: strided memref of any type values</li><li><code>output</code>: strided memref of any type values</li></ol><h4 id=attributes>Attributes:</h4><table><thead><tr><th align=center>Attribute</th><th align=center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td align=center><code>strides</code></td><td align=center><code>ArrayAttr</code></td><td>64-bit integer array attribute attribute</td></tr><tr><td align=center><code>dilations</code></td><td align=center><code>ArrayAttr</code></td><td>64-bit integer array attribute attribute</td></tr><tr><td align=center><code>padding</code></td><td align=center><code>DenseIntElementsAttr</code></td><td>64-bit signless integer elements attribute attribute</td></tr></tbody></table><h4 id=results>Results:</h4><h3 id=linalgcopy-linalgcopyop>linalg.copy (linalg::CopyOp)</h3><h4 id=description-1>Description:</h4><p>Copies the data in the input view into the output view.</p><p>Usage:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>linalg<span class=p>.</span>copy<span class=p>(</span><span class=nv>%arg0</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
                            <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
</code></pre></div><p>One possible lowering to loop form is:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%0</span> <span class=p>=</span> linalg<span class=p>.</span>dim <span class=nv>%arg0</span><span class=p>,</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
loop<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%0</span> step <span class=nv>%c1</span> <span class=p>{</span>
  <span class=nv>%1</span> <span class=p>=</span> load <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
  store <span class=nv>%1</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
<span class=p>}</span>
</code></pre></div><p>Optionally, can take <code>input_permutation</code> and <code>output_permutation</code> attributes
to reorder the dimensions of the input and output views.</p><p>Usage:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>linalg<span class=p>.</span>copy<span class=p>(</span><span class=nv>%arg0</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>)</span> <span class=p>{</span>inputPermutation <span class=p>:</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i<span class=p>,</span> k<span class=p>,</span> j<span class=p>)</span><span class=p>,</span>
                           outputPermutation <span class=p>:</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>k<span class=p>,</span> j<span class=p>,</span> i<span class=p>)</span><span class=p>}</span> <span class=p>:</span>
  <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
  <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
</code></pre></div><p>One possible lowering to loop form is:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%0</span> <span class=p>=</span> linalg<span class=p>.</span>dim <span class=nv>%arg0</span><span class=p>,</span> <span class=m>0</span>
<span class=nv>%1</span> <span class=p>=</span> linalg<span class=p>.</span>dim <span class=nv>%arg0</span><span class=p>,</span> <span class=m>1</span>
<span class=nv>%2</span> <span class=p>=</span> linalg<span class=p>.</span>dim <span class=nv>%arg0</span><span class=p>,</span> <span class=m>2</span>
loop<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=err>%</span><span class=p>{</span><span class=p>{</span><span class=p>.</span><span class=p>*</span><span class=p>}</span><span class=p>}</span> step <span class=nv>%c1</span> <span class=p>{</span>
  loop<span class=p>.</span>for <span class=nv>%i1</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=err>%</span><span class=p>{</span><span class=p>{</span><span class=p>.</span><span class=p>*</span><span class=p>}</span><span class=p>}</span> step <span class=nv>%c1</span> <span class=p>{</span>
    loop<span class=p>.</span>for <span class=nv>%i2</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=err>%</span><span class=p>{</span><span class=p>{</span><span class=p>.</span><span class=p>*</span><span class=p>}</span><span class=p>}</span> step <span class=nv>%c1</span> <span class=p>{</span>
      <span class=nv>%3</span> <span class=p>=</span> load <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i2</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>]</span> <span class=p>:</span>
              <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
      store <span class=nv>%3</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>[</span><span class=nv>%i2</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>,</span> <span class=nv>%i0</span><span class=p>]</span> <span class=p>:</span>
              <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
</code></pre></div><p>The views are expected to be compatible for correctness but this is not
enforced at the moment.</p><h4 id=operands-1>Operands:</h4><ol><li><code>input</code>: strided memref of any type values</li><li><code>output</code>: strided memref of any type values</li></ol><h4 id=attributes-1>Attributes:</h4><table><thead><tr><th align=center>Attribute</th><th align=center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td align=center><code>inputPermutation</code></td><td align=center><code>AffineMapAttr</code></td><td>AffineMap attribute attribute</td></tr><tr><td align=center><code>outputPermutation</code></td><td align=center><code>AffineMapAttr</code></td><td>AffineMap attribute attribute</td></tr></tbody></table><h4 id=results-1>Results:</h4><h3 id=linalgdot-linalgdotop>linalg.dot (linalg::DotOp)</h3><h4 id=description-2>Description:</h4><h4 id=operands-2>Operands:</h4><ol><li>«unnamed»: strided memref of any type values of rank 1</li><li>«unnamed»: strided memref of any type values of rank 1</li><li>«unnamed»: strided memref of any type values of rank 0</li></ol><h4 id=attributes-2>Attributes:</h4><h4 id=results-2>Results:</h4><h3 id=linalgfill-linalgfillop>linalg.fill (linalg::FillOp)</h3><h4 id=description-3>Description:</h4><h4 id=operands-3>Operands:</h4><ol><li><code>output</code>: strided memref of any type values</li><li><code>value</code>: floating-point or signless integer or vector of any type values</li></ol><h4 id=attributes-3>Attributes:</h4><h4 id=results-3>Results:</h4><h3 id=linalggeneric-linalggenericop>linalg.generic (linalg::GenericOp)</h3><h4 id=description-4>Description:</h4><p>Generic Linalg op form where the key properties of the computation are
specified as attributes. In pretty form, a linalg.generic op is written as:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  linalg<span class=p>.</span>generic <span class=nv>#trait_attribute</span> <span class=nv>%A</span><span class=p>,</span> <span class=nv>%B</span><span class=p>,</span> <span class=nv>%C</span> <span class=p>{</span>other<span class=err>-</span>attributes<span class=p>}</span> <span class=p>:</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
</code></pre></div><p>Where #trait_attributes is an alias of a dictionary attribute containing:</p><ul><li>args_in: an I64Attr representing the number of input (readonly) views</li><li>args_out: an I64Attr representing the number of output (readwrite) views</li><li>doc [optional]: a documentation string</li><li>fun: a FlatSymbolRefAttr that must resolve to an existing function
symbol. To support inplace updates in a generic fashion, the signature
of the function must be:<pre><code>  fun([input views element types], [output views element types])
    -&gt; ([output views element types])
</code></pre></li><li>indexing_maps: a list of AffineMapAttr, one AffineMapAttr per each input
and output view. Such AffineMapAttr specifies the mapping between the
loops and the indexing within each view.</li><li>library_call [optional]: a StringAttr containing the name of an
external library function that the linalg.generic operation maps to.
The external library is assumed to be dynamically linked and no strong
compile-time guarantees are provided. In the absence of such a library
call, linalg.generic will always lower to loops.</li><li>iterator_types: an ArrayAttr specifying the type of the enclosing loops.
Each element of the list represents and iterator of one of the following
types:
parallel, reduction, window</li></ul><p>Example:
Defining a #matmul_trait attribute in MLIR can be done as follows:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=kt>func</span> <span class=nf>@fma</span><span class=p>(</span><span class=nv>%a</span><span class=p>:</span> <span class=k>f32</span><span class=p>,</span> <span class=nv>%b</span><span class=p>:</span> <span class=k>f32</span><span class=p>,</span> <span class=nv>%c</span><span class=p>:</span> <span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span> <span class=p>{</span>
    <span class=nv>%d</span> <span class=p>=</span> mulf <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>:</span> <span class=k>f32</span>
    <span class=nv>%e</span> <span class=p>=</span> addf <span class=nv>%c</span><span class=p>,</span> <span class=nv>%d</span><span class=p>:</span> <span class=k>f32</span>
    <span class=kt>return</span> <span class=nv>%e</span><span class=p>:</span> <span class=k>f32</span>
  <span class=p>}</span>
  <span class=nv>#matmul_accesses</span> <span class=p>=</span> <span class=p>[</span>
    <span class=p>(</span>m<span class=p>,</span> n<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>m<span class=p>,</span> k<span class=p>)</span><span class=p>,</span>
    <span class=p>(</span>m<span class=p>,</span> n<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>k<span class=p>,</span> n<span class=p>)</span><span class=p>,</span>
    <span class=p>(</span>m<span class=p>,</span> n<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>m<span class=p>,</span> n<span class=p>)</span>
  <span class=p>]</span>
  <span class=nv>#matmul_trait</span> <span class=p>=</span> <span class=p>{</span>
    <span class=nl>doc =</span> <span class=s>&#34;C(m, n) += A(m, k) * B(k, n)&#34;</span><span class=p>,</span>
    <span class=nl>fun =</span> <span class=nf>@fma</span><span class=p>,</span>
    <span class=nl>indexing_maps =</span> <span class=nv>#matmul_accesses</span><span class=p>,</span>
    <span class=nl>library_call =</span> <span class=s>&#34;linalg_matmul&#34;</span><span class=p>,</span>
    <span class=nl>n_views =</span> <span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>1</span><span class=p>]</span><span class=p>,</span>
    <span class=nl>iterator_types =</span> <span class=p>[</span><span class=s>&#34;parallel&#34;</span><span class=p>,</span> <span class=s>&#34;parallel&#34;</span><span class=p>,</span> <span class=s>&#34;reduction&#34;</span><span class=p>]</span>
  <span class=p>}</span>
</code></pre></div><p>And can be reused in multiple places as:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  linalg<span class=p>.</span>generic <span class=nv>#matmul_trait</span> <span class=nv>%A</span><span class=p>,</span> <span class=nv>%B</span><span class=p>,</span> <span class=nv>%C</span> <span class=p>[</span>other<span class=err>-</span>attributes<span class=p>]</span> <span class=p>:</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
</code></pre></div><p>This may lower to either:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  call <span class=nf>@linalg_matmul</span><span class=p>(</span><span class=nv>%A</span><span class=p>,</span> <span class=nv>%B</span><span class=p>,</span> <span class=nv>%C</span><span class=p>)</span> <span class=p>:</span>
    <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
     <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
     <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>)</span>
    <span class=p>-&gt;</span> <span class=p>(</span><span class=p>)</span>
</code></pre></div><p>or IR resembling:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>loop<span class=p>.</span>for <span class=nv>%m</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%M</span> step <span class=nv>%c1</span> <span class=p>{</span>
  loop<span class=p>.</span>for <span class=nv>%n</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%N</span> step <span class=nv>%c1</span> <span class=p>{</span>
    loop<span class=p>.</span>for <span class=nv>%k</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%K</span> step <span class=nv>%c1</span> <span class=p>{</span>
      <span class=nv>%a</span> <span class=p>=</span> load <span class=nv>%A</span><span class=p>[</span><span class=nv>%m</span><span class=p>,</span> <span class=nv>%k</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
      <span class=nv>%b</span> <span class=p>=</span> load <span class=nv>%B</span><span class=p>[</span><span class=nv>%k</span><span class=p>,</span> <span class=nv>%n</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
      <span class=nv>%c</span> <span class=p>=</span> load <span class=nv>%C</span><span class=p>[</span><span class=nv>%m</span><span class=p>,</span> <span class=nv>%n</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
      <span class=nv>%d</span> <span class=p>=</span> call <span class=nf>@func_of_elements</span><span class=p>(</span><span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>,</span> <span class=nv>%c</span><span class=p>)</span>
             <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>,</span> <span class=k>f32</span><span class=p>,</span> <span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span>
      store <span class=nv>%d</span><span class=p>,</span> <span class=nv>%C</span><span class=p>[</span><span class=nv>%m</span><span class=p>,</span> <span class=nv>%n</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
    <span class=p>}</span>
  <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><p>To allow progressive lowering from the value world (a.k.a tensor values) to
the buffer world (a.k.a memref values), a <code>linalg.generic</code> op accepts
mixing input and output ranked tensor values with input and output memrefs.</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=nv>%C</span> <span class=p>=</span> linalg<span class=p>.</span>generic <span class=nv>#trait_attribute</span> <span class=nv>%A</span><span class=p>,</span> <span class=nv>%B</span> <span class=p>{</span>other<span class=err>-</span>attributes<span class=p>}</span> <span class=p>:</span>
    <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
    <span class=p>-&gt;</span> <span class=p>(</span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span>
</code></pre></div><p>In this case, the number of outputs (args_out) must match the sum of (1) the
number of output buffer operands and (2) the number of tensor return values.
The semantics is that the <code>linalg.indexed_generic</code> op produces (i.e.
allocates and fills) its tensor return values.</p><p>Tensor values must be legalized by a buffer allocation pass before most
transformations can be applied. Such legalization moves tensor return values
into output buffer operands and updates the region arguments accordingly.</p><p>Transformations that create control-flow around linalg.indexed_generic
operations are not expected to work with tensors because SSA values do not
escape naturally. Still, transformations and rewrites that take advantage of
tensor SSA values are expected to be useful and will be added in the near
future.</p><h4 id=operands-4>Operands:</h4><ol><li><code>views</code>: anonymous_323</li></ol><h4 id=attributes-4>Attributes:</h4><table><thead><tr><th align=center>Attribute</th><th align=center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td align=center><code>args_in</code></td><td align=center><code>IntegerAttr</code></td><td>64-bit signless integer attribute attribute</td></tr><tr><td align=center><code>args_out</code></td><td align=center><code>IntegerAttr</code></td><td>64-bit signless integer attribute attribute</td></tr><tr><td align=center><code>indexing_maps</code></td><td align=center><code>ArrayAttr</code></td><td>AffineMap array attribute attribute</td></tr><tr><td align=center><code>iterator_types</code></td><td align=center><code>ArrayAttr</code></td><td>array attribute attribute</td></tr><tr><td align=center><code>doc</code></td><td align=center><code>StringAttr</code></td><td>string attribute attribute</td></tr><tr><td align=center><code>fun</code></td><td align=center><code>FlatSymbolRefAttr</code></td><td>flat symbol reference attribute attribute</td></tr><tr><td align=center><code>library_call</code></td><td align=center><code>StringAttr</code></td><td>string attribute attribute</td></tr></tbody></table><h4 id=results-4>Results:</h4><ol><li><code>output_tensors</code>: ranked tensor of any type values</li></ol><h3 id=linalgindexed_generic-linalgindexedgenericop>linalg.indexed_generic (linalg::IndexedGenericOp)</h3><h4 id=description-5>Description:</h4><p>Indexed Generic Linalg op form where the key properties of the computation
are specified as attributes. In pretty form, a linalg.indexed_generic op is
written as:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  linalg<span class=p>.</span><span class=k>index</span>ed_generic <span class=nv>#trait_attribute</span> <span class=nv>%A</span><span class=p>,</span> <span class=nv>%B</span><span class=p>,</span> <span class=nv>%C</span> <span class=p>{</span>other<span class=err>-</span>attributes<span class=p>}</span> <span class=p>:</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
</code></pre></div><p>Where #trait_attributes is an alias of a dictionary attribute containing:</p><ul><li>args_in: an I64Attr representing the number of input (readonly) views</li><li>args_out: an I64Attr representing the number of output (readwrite) views</li><li>doc [optional]: a documentation string</li><li>fun: a FlatSymbolRefAttr that must resolve to an existing function
symbol. To support inplace updates in a generic fashion, the signature
of the function must be:<pre><code>  fun([index types of induction variables], [input views element types],
      [output views element types]) -&gt; ([output views element types])
</code></pre></li><li>indexing_maps: a list of AffineMapAttr, one AffineMapAttr per each input
and output view. Such AffineMapAttr specifies the mapping between the
loops and the indexing within each view.</li><li>library_call [optional]: a StringAttr containing the name of an
external library function that the linalg.indexed_generic operation
maps to. The external library is assumed to be dynamically linked and
no strong compile-time guarantees are provided. In the absence of such
a library call, linalg.indexed_generic will always lower to loops.</li><li>iterator_types: an ArrayAttr they type of the enclosing loops; Each
element of the list represents and iterator of one of the following
types:
parallel, reduction, window</li></ul><p>Example:
Defining a #matmul_trait attribute in MLIR can be done as follows:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=kt>func</span> <span class=nf>@fma</span><span class=p>(</span><span class=nv>%offset_m</span><span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%offset_n</span><span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%offset_k</span><span class=p>:</span> <span class=k>index</span><span class=p>,</span>
            <span class=nv>%a</span><span class=p>:</span> <span class=k>f32</span><span class=p>,</span> <span class=nv>%b</span><span class=p>:</span> <span class=k>f32</span><span class=p>,</span> <span class=nv>%c</span><span class=p>:</span> <span class=k>f32</span><span class=p>)</span>
    <span class=p>-&gt;</span> <span class=k>f32</span>
  <span class=p>{</span>
    <span class=s>&#34;some_optional_condition&#34;</span><span class=p>(</span><span class=nv>%offset_m</span><span class=p>,</span> <span class=nv>%offset_n</span><span class=p>,</span> <span class=nv>%offset_k</span><span class=p>)</span>
    <span class=nv>%d</span> <span class=p>=</span> mulf <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>:</span> <span class=k>f32</span>
    <span class=nv>%e</span> <span class=p>=</span> addf <span class=nv>%c</span><span class=p>,</span> <span class=nv>%d</span><span class=p>:</span> <span class=k>f32</span>
    <span class=kt>return</span> <span class=nv>%e</span><span class=p>:</span> <span class=k>f32</span>
  <span class=p>}</span>
  <span class=nv>#matmul_accesses</span> <span class=p>=</span> <span class=p>[</span>
    <span class=p>(</span>m<span class=p>,</span> n<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>m<span class=p>,</span> k<span class=p>)</span><span class=p>,</span>
    <span class=p>(</span>m<span class=p>,</span> n<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>k<span class=p>,</span> n<span class=p>)</span><span class=p>,</span>
    <span class=p>(</span>m<span class=p>,</span> n<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>m<span class=p>,</span> n<span class=p>)</span>
  <span class=p>]</span>
  <span class=nv>#matmul_trait</span> <span class=p>=</span> <span class=p>{</span>
    <span class=nl>doc =</span> <span class=s>&#34;C(m, n) += A(m, k) * B(k, n)&#34;</span><span class=p>,</span>
    <span class=nl>fun =</span> <span class=nf>@fma</span><span class=p>,</span>
    <span class=nl>indexing_maps =</span> <span class=nv>#matmul_accesses</span><span class=p>,</span>
    <span class=nl>library_call =</span> <span class=s>&#34;linalg_matmul&#34;</span><span class=p>,</span>
    <span class=nl>n_views =</span> <span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>1</span><span class=p>]</span><span class=p>,</span>
    <span class=nl>iterator_types =</span> <span class=p>[</span><span class=s>&#34;parallel&#34;</span><span class=p>,</span> <span class=s>&#34;parallel&#34;</span><span class=p>,</span> <span class=s>&#34;reduction&#34;</span><span class=p>]</span>
  <span class=p>}</span>
</code></pre></div><p>And can be reused in multiple places as:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  linalg<span class=p>.</span><span class=k>index</span>ed_generic <span class=nv>#matmul_trait</span> <span class=nv>%A</span><span class=p>,</span> <span class=nv>%B</span><span class=p>,</span> <span class=nv>%C</span> <span class=p>[</span>other<span class=err>-</span>attributes<span class=p>]</span> <span class=p>:</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
</code></pre></div><p>This may lower to either:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  call <span class=nf>@linalg_matmul</span><span class=p>(</span><span class=nv>%offset_m</span><span class=p>,</span> <span class=nv>%offset_n</span><span class=p>,</span> <span class=nv>%offset_k</span><span class=p>,</span> <span class=nv>%A</span><span class=p>,</span> <span class=nv>%B</span><span class=p>,</span> <span class=nv>%C</span><span class=p>)</span> <span class=p>:</span>
    <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
     <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>,</span>
     <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span><span class=p>)</span>
    <span class=p>-&gt;</span> <span class=p>(</span><span class=p>)</span>
</code></pre></div><p>or IR resembling:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>loop<span class=p>.</span>for <span class=nv>%m</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%M</span> step <span class=nv>%c1</span> <span class=p>{</span>
  loop<span class=p>.</span>for <span class=nv>%n</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%N</span> step <span class=nv>%c1</span> <span class=p>{</span>
    loop<span class=p>.</span>for <span class=nv>%k</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%K</span> step <span class=nv>%c1</span> <span class=p>{</span>
      <span class=nv>%a</span> <span class=p>=</span> load <span class=nv>%A</span><span class=p>[</span><span class=nv>%m</span><span class=p>,</span> <span class=nv>%k</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
      <span class=nv>%b</span> <span class=p>=</span> load <span class=nv>%B</span><span class=p>[</span><span class=nv>%k</span><span class=p>,</span> <span class=nv>%n</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
      <span class=nv>%c</span> <span class=p>=</span> load <span class=nv>%C</span><span class=p>[</span><span class=nv>%m</span><span class=p>,</span> <span class=nv>%n</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
      <span class=nv>%d</span> <span class=p>=</span> call <span class=nf>@func_of_elements_and_indices</span><span class=p>(</span><span class=nv>%m</span><span class=p>,</span> <span class=nv>%n</span><span class=p>,</span> <span class=nv>%k</span><span class=p>,</span> <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>,</span> <span class=nv>%c</span><span class=p>)</span>
             <span class=p>:</span> <span class=p>(</span><span class=k>index</span><span class=p>,</span> <span class=k>index</span><span class=p>,</span> <span class=k>index</span><span class=p>,</span> <span class=k>f32</span><span class=p>,</span> <span class=k>f32</span><span class=p>,</span> <span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span>
      store <span class=nv>%d</span><span class=p>,</span> <span class=nv>%C</span><span class=p>[</span><span class=nv>%m</span><span class=p>,</span> <span class=nv>%n</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
    <span class=p>}</span>
  <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><p>To allow progressive lowering from the value world (a.k.a tensor values) to
the buffer world (a.k.a memref values), a <code>linalg.indexed_generic</code> op
accepts mixing input and output ranked tensor values with input and output
memrefs.</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=nv>%C</span> <span class=p>=</span> linalg<span class=p>.</span><span class=k>index</span>ed_generic <span class=nv>#trait_attribute</span> <span class=nv>%A</span><span class=p>,</span> <span class=nv>%B</span> <span class=p>{</span>other<span class=err>-</span>attributes<span class=p>}</span>
  <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span>
    <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_specification<span class=p>&gt;</span>
    <span class=p>-&gt;</span> <span class=p>(</span><span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span>
</code></pre></div><p>In this case, the number of outputs (args_out) must match the sum of (1) the
number of output buffer operands and (2) the number of tensor return values.
The semantics is that the <code>linalg.indexed_generic</code> op produces (i.e.
allocates and fills) its return values.</p><p>Tensor values must be legalized by a buffer allocation pass before most
transformations can be applied. Such legalization moves tensor return values
into output buffer operands and updates the region argument accordingly.</p><p>Transformations that create control-flow around linalg.indexed_generic
operations are not expected to work with tensors because SSA values do not
escape naturally. Still, transformations and rewrites that take advantage of
tensor SSA values are expected to be useful and will be added in the near
future.</p><h4 id=operands-5>Operands:</h4><ol><li><code>views</code>: anonymous_323</li></ol><h4 id=attributes-5>Attributes:</h4><table><thead><tr><th align=center>Attribute</th><th align=center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td align=center><code>args_in</code></td><td align=center><code>IntegerAttr</code></td><td>64-bit signless integer attribute attribute</td></tr><tr><td align=center><code>args_out</code></td><td align=center><code>IntegerAttr</code></td><td>64-bit signless integer attribute attribute</td></tr><tr><td align=center><code>indexing_maps</code></td><td align=center><code>ArrayAttr</code></td><td>AffineMap array attribute attribute</td></tr><tr><td align=center><code>iterator_types</code></td><td align=center><code>ArrayAttr</code></td><td>array attribute attribute</td></tr><tr><td align=center><code>doc</code></td><td align=center><code>StringAttr</code></td><td>string attribute attribute</td></tr><tr><td align=center><code>fun</code></td><td align=center><code>FlatSymbolRefAttr</code></td><td>flat symbol reference attribute attribute</td></tr><tr><td align=center><code>library_call</code></td><td align=center><code>StringAttr</code></td><td>string attribute attribute</td></tr></tbody></table><h4 id=results-5>Results:</h4><ol><li><code>output_tensors</code>: ranked tensor of any type values</li></ol><h3 id=linalgrange-linalgrangeop>linalg.range (linalg::RangeOp)</h3><p>Create a <code>range</code> type value, used to create <code>view</code>s</p><h4 id=description-6>Description:</h4><p>The <code>linalg.range</code> op creates a <code>!linalg.range</code> from 3 values of type
<code>index</code> that represent the min, max and step values of the <code>range</code>. This
type does not pass function boundaries at the moment.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=nv>%3</span> <span class=p>=</span> linalg<span class=p>.</span>range <span class=nv>%0</span><span class=p>:</span><span class=nv>%1</span><span class=p>:</span><span class=nv>%2</span> <span class=p>:</span> <span class=p>!</span>linalg<span class=p>.</span>range
</code></pre></div><h4 id=operands-6>Operands:</h4><ol><li><code>min</code>: index</li><li><code>max</code>: index</li><li><code>step</code>: index</li></ol><h4 id=attributes-6>Attributes:</h4><h4 id=results-6>Results:</h4><ol><li>«unnamed»: range</li></ol><h3 id=linalgreshape-linalgreshapeop>linalg.reshape (linalg::ReshapeOp)</h3><p>linalg.reshape produces a new view into the operand view</p><h4 id=description-7>Description:</h4><p>The <code>linalg.reshape</code> op produces a new view whose sizes are a reassociation
of the original <code>view</code>. Depending on whether or not the reassociated
MemRefType is contiguous, the resulting memref may require explicit alloc
and copies.</p><p>A reassociation is defined as a continuous grouping of dimensions and is
represented with an affine map array attribute. In the future,
non-continuous groupings may be allowed (i.e. permutations, reindexings
etc).</p><p>For now, it is assumed that either:</p><ol><li>a reassociation produces and consumes contiguous MemRefType or,</li><li>the reshape op will be folded into its consumers (by changing the shape
of the computations).
All other cases are undefined behavior and a reshape op may not lower to
LLVM if it cannot be proven statically that it does not require alloc+copy.</li></ol><p>A reshape may either collapse or expand dimensions, depending on the
relationship between source and target memref ranks. The verification rule
is that the reassociation maps are applied to the memref with the larger
rank to obtain the memref with the smaller rank. In the case of a dimension
expansion, the reassociation maps can be interpreted as inverse maps.</p><p>Examples:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>   <span class=c>// Dimension collapse (i, j) -&gt; i&#39; and k -&gt; k&#39;
</span><span class=c></span>   <span class=nv>%1</span> <span class=p>=</span> linalg<span class=p>.</span>reshape <span class=nv>%0</span> <span class=p>[</span><span class=p>(</span>i<span class=p>,</span> j<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>)</span><span class=p>,</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>k<span class=p>)</span><span class=p>]</span> <span class=p>:</span>
     <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x</span><span class=k>f32</span><span class=p>,</span> stride_spec<span class=p>&gt;</span> into <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_spec_2<span class=p>&gt;</span>
</code></pre></div><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>   <span class=c>// Dimension expansion i -&gt; (i&#39;, j&#39;) and (k) -&gt; (k&#39;)
</span><span class=c></span>   <span class=nv>%1</span> <span class=p>=</span> linalg<span class=p>.</span>reshape <span class=nv>%0</span> <span class=p>[</span><span class=p>(</span>i<span class=p>,</span> j<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>)</span><span class=p>,</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>k<span class=p>)</span><span class=p>]</span> <span class=p>:</span>
     <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_spec<span class=p>&gt;</span> into <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x</span><span class=k>f32</span><span class=p>,</span> stride_spec_2<span class=p>&gt;</span>
</code></pre></div><h4 id=operands-7>Operands:</h4><ol><li><code>view</code>: strided memref of any type values</li></ol><h4 id=attributes-7>Attributes:</h4><table><thead><tr><th align=center>Attribute</th><th align=center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td align=center><code>reassociation</code></td><td align=center><code>ArrayAttr</code></td><td>AffineMap array attribute attribute</td></tr></tbody></table><h4 id=results-7>Results:</h4><ol><li>«unnamed»: strided memref of any type values</li></ol><h3 id=linalgslice-linalgsliceop>linalg.slice (linalg::SliceOp)</h3><p>Produce a rank-reduced <code>subview</code> of a base <code>view</code>.</p><h4 id=description-8>Description:</h4><p>The <code>linalg.slice</code> op allows defining a subregion of a smaller rank than the
operand <code>view</code> within the underlying buffer.</p><p>A <code>linalg.slice</code> op takes a view and a variadic number of indexings and
produces a <code>view</code> of the same elemental type. An indexing is either:</p><ol><li>a <code>linalg.range</code>, in which case it does not reduce the rank of the
parent <code>view</code> along the corresponding dimension.</li><li>an <code>index</code>, in which case it reduces the rank of the parent view by
one.</li></ol><p>If an indexing extends past the size of the <code>view</code>, this is undefined
behavior. Ideally the <code>linalg.slice</code> operation would automatically truncate
it to be within bounds but there are tradeoffs involved now that <code>std.view</code>
is a standard op.</p><p>Examples:</p><ol><li>rank-preserving <code>slice</code>:</li></ol><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=nv>%4</span> <span class=p>=</span> linalg<span class=p>.</span>slice <span class=nv>%0</span><span class=p>[</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_spec<span class=p>&gt;</span><span class=p>,</span>
    <span class=p>!</span>linalg<span class=p>.</span>range<span class=p>,</span> <span class=p>!</span>linalg<span class=p>.</span>range<span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_spec<span class=p>&gt;</span>
</code></pre></div><ol start=2><li>rank-reducing <code>slice</code> (from 2-D to 1-D):</li></ol><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=nv>%4</span> <span class=p>=</span> linalg<span class=p>.</span>slice <span class=nv>%0</span><span class=p>[</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_spec<span class=p>&gt;</span><span class=p>,</span>
    <span class=k>index</span><span class=p>,</span> <span class=p>!</span>linalg<span class=p>.</span>range<span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_spec<span class=p>&gt;</span>
</code></pre></div><ol start=3><li>rank-reducing <code>slice</code> (from 2-D to 0-D):</li></ol><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>  <span class=nv>%4</span> <span class=p>=</span> linalg<span class=p>.</span>slice <span class=nv>%0</span><span class=p>[</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_spec<span class=p>&gt;</span><span class=p>,</span>
    <span class=k>index</span><span class=p>,</span> <span class=k>index</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_spec<span class=p>&gt;</span>
</code></pre></div><h4 id=operands-8>Operands:</h4><ol><li><code>view</code>: strided memref of any type values</li><li><code>indexings</code>: range or index</li></ol><h4 id=attributes-8>Attributes:</h4><h4 id=results-8>Results:</h4><ol><li>«unnamed»: strided memref of any type values</li></ol><h3 id=linalgtranspose-linalgtransposeop>linalg.transpose (linalg::TransposeOp)</h3><p><code>transpose</code> produces a new strided memref (metadata-only)</p><h4 id=description-9>Description:</h4><p>The <code>linalg.transpose</code> op produces a strided memref whose sizes and strides
are a permutation of the original <code>view</code>. This is a pure metadata
transformation.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>   <span class=nv>%1</span> <span class=p>=</span> linalg<span class=p>.</span>transpose <span class=nv>%0</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>j<span class=p>,</span> i<span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>,</span> stride_spec<span class=p>&gt;</span>
</code></pre></div><h4 id=operands-9>Operands:</h4><ol><li><code>view</code>: strided memref of any type values</li></ol><h4 id=attributes-9>Attributes:</h4><table><thead><tr><th align=center>Attribute</th><th align=center>MLIR Type</th><th>Description</th></tr></thead><tbody><tr><td align=center><code>permutation</code></td><td align=center><code>AffineMapAttr</code></td><td>AffineMap attribute attribute</td></tr></tbody></table><h4 id=results-9>Results:</h4><ol><li>«unnamed»: strided memref of any type values</li></ol><h3 id=linalgyield-linalgyieldop>linalg.yield (linalg::YieldOp)</h3><p>Linalg yield operation</p><h4 id=description-10>Description:</h4><p><code>linalg.yield</code> is a special terminator operation for blocks inside regions
in <code>linalg</code> generic ops. It returns values to the immediately enclosing
<code>linalg</code> generic op.</p><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>   linalg<span class=p>.</span>yield <span class=nv>%f0</span><span class=p>,</span> <span class=nv>%f1</span> <span class=p>:</span> <span class=k>f32</span><span class=p>,</span> <span class=k>f32</span>
</code></pre></div><h4 id=operands-10>Operands:</h4><ol><li><code>values</code>: any type</li></ol><h4 id=attributes-10>Attributes:</h4><h4 id=results-10>Results:</h4><h3 id=linalgmatmul-linalgmatmulop>linalg.matmul (linalg::MatmulOp)</h3><h4 id=description-11>Description:</h4><h4 id=operands-11>Operands:</h4><ol><li>«unnamed»: strided memref of any type values of rank 2</li><li>«unnamed»: strided memref of any type values of rank 2</li><li>«unnamed»: strided memref of any type values of rank 2</li></ol><h4 id=attributes-11>Attributes:</h4><h4 id=results-11>Results:</h4><h3 id=linalgmatvec-linalgmatvecop>linalg.matvec (linalg::MatvecOp)</h3><h4 id=description-12>Description:</h4><h4 id=operands-12>Operands:</h4><ol><li>«unnamed»: strided memref of any type values of rank 2</li><li>«unnamed»: strided memref of any type values of rank 1</li><li>«unnamed»: strided memref of any type values of rank 1</li></ol><h4 id=attributes-12>Attributes:</h4><h4 id=results-12>Results:</h4><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=/docs/Dialects/GPUOps/ title="Dialect 'gpu' definition"><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - Dialect 'gpu' definition</a>
<a class="nav nav-next" href=/docs/Dialects/LoopOps/ title="Dialect 'loop' definition">Next - Dialect 'loop' definition <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=/talks/>Talks and Related Publications</a></li><li><a href=/users/>Users of MLIR</a></li><li class=has-sub-menu><a href=/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=/getting_started/Contributing/>How to Contribute</a></li><li><a href=/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=/getting_started/openprojects/>Open Projects</a></li><li><a href=/getting_started/Glossary/>Glossary</a></li><li><a href=/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class="parent has-sub-menu"><a href=/docs/Dialects/>Dialects<span class="mark opened">-</span></a><ul class=sub-menu><li><a href=/docs/Dialects/Affine/>Affine Dialect</a></li><li><a href=/docs/Dialects/AffineOps/>Dialect 'affine' definition</a></li><li><a href=/docs/Dialects/FxpMathOps/>Dialect 'fxpmath' definition</a></li><li><a href=/docs/Dialects/GPUOps/>Dialect 'gpu' definition</a></li><li class=active><a href=/docs/Dialects/LinalgDoc/>Dialect 'linalg' definition</a></li><li><a href=/docs/Dialects/LoopOps/>Dialect 'loop' definition</a></li><li><a href=/docs/Dialects/NVVMOps/>Dialect 'nvvm' definition</a></li><li><a href=/docs/Dialects/OpenMPOps/>Dialect 'omp' definition</a></li><li><a href=/docs/Dialects/QuantOps/>Dialect 'quant' definition</a></li><li><a href=/docs/Dialects/ROCDLOps/>Dialect 'rocdl' definition</a></li><li><a href=/docs/Dialects/SPIRVOps/>Dialect 'spv' definition</a></li><li><a href=/docs/Dialects/VectorOps/>Dialect 'vector' definition</a></li><li><a href=/docs/Dialects/GPU/>GPU Dialect</a></li><li><a href=/docs/Dialects/Linalg/>Linalg Dialect</a></li><li><a href=/docs/Dialects/LLVM/>LLVM IR Dialect</a></li><li><a href=/docs/Dialects/SPIR-V/>SPIR-V Dialect</a></li><li><a href=/docs/Dialects/Standard/>Standard Dialect</a></li><li><a href=/docs/Dialects/Vector/>Vector Dialect</a></li></ul></li><li class=has-sub-menu><a href=/docs/Tutorials/Toy/>Toy<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Tutorial Introduction</a></li><li><a href=/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li><a href=/docs/EDSC/>Background: declarative builders API</a></li><li><a href=/docs/ConversionToLLVMDialect/>Conversion to the LLVM Dialect</a></li><li><a href=/docs/CreatingADialect/>Creating a Dialect</a></li><li><a href=/docs/DialectConversion/>Dialect Conversion</a></li><li><a href=/docs/Diagnostics/>Introduction and Usage Guide to MLIR's Diagnostics Infrastructure</a></li><li><a href=/docs/Interfaces/>Introduction to MLIR Interfaces</a></li><li><a href=/docs/Traits/>Introduction to MLIR Operation Traits</a></li><li><a href=/docs/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=/docs/GenericDAGRewriter/>MLIR Generic DAG Rewriter Infrastructure</a></li><li><a href=/docs/Passes/>MLIR Passes</a></li><li><a href=/docs/Quantization/>MLIR Quantization</a></li><li><a href=/docs/Rationale/>MLIR Rationale</a></li><li><a href=/docs/LangRef/>MLIR Specification</a></li><li><a href=/docs/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=/docs/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=/docs/Canonicalization/>Operation Canonicalization in MLIR</a></li><li><a href=/docs/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li><a href=/docs/DefiningAttributesAndTypes/>Quickstart tutorial to defining custom dialect attributes and types</a></li><li><a href=/docs/ShapeInference/>Shape inference</a></li><li><a href=/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=/docs/OpDefinitions/>Table-driven Operation Definition Specification (ODS)</a></li><li><a href=/docs/UsageOfConst/>Usage of 'Const' in MLIR, for core IR types</a></li><li><a href=/docs/WritingAPass/>Writing a Pass</a></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>